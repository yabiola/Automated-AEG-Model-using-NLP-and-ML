{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7bd838",
   "metadata": {},
   "source": [
    "# MODEL TRAINING AND EVALUATION\n",
    "Following the data preprocessing steps conducted in the \"data_preprocessing.ipynb\" file. This code file called \"model_training\" contains a comprehensive machine learning pipeline for essay grading using the processed data from the data_preprocessing file. \n",
    "The code contains additional text processing, model training and evaluation and, the visualization of the results.\n",
    "\n",
    "## Text Processing\n",
    "1. Tokenizing and vectorizing the essay text using Count Vectorization.\n",
    "2. Generating Word2Vec word embeddings for the essay text.\n",
    "\n",
    "## Model Training and Evaluation\n",
    "1. Training and evaluating a Support Vector Machine (SVM) regression model.\n",
    "2. Training and evaluating a Random Forest regression model.\n",
    "3. Training and evaluating multiple layers of LSTM models with Word2Vec embeddings.\n",
    "4. Saving the trained models to files for future use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1526f",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab7ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np   # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns  # For enhanced data visualization\n",
    "%matplotlib inline\n",
    "import warnings  # For suppressing warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import os  # For operating system-related functions\n",
    "\n",
    "import nltk  # Natural Language Toolkit for NLP tasks\n",
    "\n",
    "from gensim.models import Word2Vec  # For Word2Vec embeddings\n",
    "import joblib #For saving and loading ML models\n",
    "from sklearn.model_selection import train_test_split, KFold  # For data splitting and cross-validation\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, mean_absolute_error  # For evaluation metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # For text vectorization\n",
    "from sklearn.ensemble import RandomForestRegressor  # For Random Forest regression\n",
    "from sklearn.svm import SVR  # For Support Vector Regression\n",
    "\n",
    "from keras.layers import LSTM, Dense, Dropout  # For defining LSTM neural networks\n",
    "from keras.models import Sequential, load_model, model_from_config  # For creating and loading Keras models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb3aaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>grade</th>\n",
       "      <th>token_essay</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>preposition_count</th>\n",
       "      <th>conjunction_count</th>\n",
       "      <th>determiner_count</th>\n",
       "      <th>misspelled_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['Dear', 'local', 'newspaper', 'I', 'think', ...</td>\n",
       "      <td>16</td>\n",
       "      <td>179</td>\n",
       "      <td>118</td>\n",
       "      <td>935</td>\n",
       "      <td>5.223464</td>\n",
       "      <td>71</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>[['Dear', 'I', 'believe', 'using', 'computers'...</td>\n",
       "      <td>17</td>\n",
       "      <td>235</td>\n",
       "      <td>141</td>\n",
       "      <td>1249</td>\n",
       "      <td>5.314894</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[['Dear', 'More', 'people', 'use', 'computers'...</td>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>105</td>\n",
       "      <td>816</td>\n",
       "      <td>5.551020</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>[['Dear', 'Local', 'Newspaper', 'I', 'found', ...</td>\n",
       "      <td>26</td>\n",
       "      <td>283</td>\n",
       "      <td>186</td>\n",
       "      <td>1678</td>\n",
       "      <td>5.929329</td>\n",
       "      <td>141</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>[['Dear', 'I', 'know', 'computers', 'positive'...</td>\n",
       "      <td>30</td>\n",
       "      <td>258</td>\n",
       "      <td>148</td>\n",
       "      <td>1391</td>\n",
       "      <td>5.391473</td>\n",
       "      <td>118</td>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   grade                                        token_essay  sentence_count  \\\n",
       "0      8  [['Dear', 'local', 'newspaper', 'I', 'think', ...              16   \n",
       "1      9  [['Dear', 'I', 'believe', 'using', 'computers'...              17   \n",
       "2      7  [['Dear', 'More', 'people', 'use', 'computers'...              14   \n",
       "3     10  [['Dear', 'Local', 'Newspaper', 'I', 'found', ...              26   \n",
       "4      8  [['Dear', 'I', 'know', 'computers', 'positive'...              30   \n",
       "\n",
       "   word_count  unique_word_count  character_count  average_word_length  \\\n",
       "0         179                118              935             5.223464   \n",
       "1         235                141             1249             5.314894   \n",
       "2         147                105              816             5.551020   \n",
       "3         283                186             1678             5.929329   \n",
       "4         258                148             1391             5.391473   \n",
       "\n",
       "   noun_count  verb_count  adj_count  adverb_count  pronoun_count  \\\n",
       "0          71          43         25            15             13   \n",
       "1          98          63         25            13             15   \n",
       "2          73          35         23             3              3   \n",
       "3         141          61         37            14              5   \n",
       "4         118          49         24            16              5   \n",
       "\n",
       "   preposition_count  conjunction_count  determiner_count  misspelled_count  \n",
       "0                  5                  0                 0                12  \n",
       "1                  8                  0                 4                17  \n",
       "2                  2                  0                 3                 8  \n",
       "3                  9                  0                 5                27  \n",
       "4                 10                  0                15                20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from the \"processed.csv\" file into a DataFrame\n",
    "df = pd.read_csv(\"processed.csv\")\n",
    "\n",
    "# Dropping the 'Unnamed: 0' column as it appears to be an extra index column\n",
    "df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame to inspect the data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c60616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the \"Models\" directory exists; if not, create it\n",
    "if not os.path.exists(\"Models\"):\n",
    "    os.mkdir(\"Models\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3beed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_results(results, title):\n",
    "    \"\"\"\n",
    "    Visualize the results using a bar plot.\n",
    "\n",
    "    Args:\n",
    "        results (dict): A dictionary containing model names as keys and their corresponding scores as values.\n",
    "        title (str): The title of the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(results.keys()), y=list(results.values()))\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66b8ad",
   "metadata": {},
   "source": [
    " Contribution 1: Evaluation of Machine Learning Models on Linguistic and Structural Features of Essays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a823a94",
   "metadata": {},
   "source": [
    "Count Vectorization: N-Gram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b881255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code uses CountVectorizer to convert text data into a bag-of-words representation\n",
    "# that includes unigrams, bigrams, and trigrams, and prepares it for modeling by creating a dense array for feature extraction.\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 1000, ngram_range=(1, 3), stop_words='english')\n",
    "count_vectors = vectorizer.fit_transform(df['token_essay'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X_cv = count_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f614ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>add stress</th>\n",
       "      <th>adult</th>\n",
       "      <th>adults</th>\n",
       "      <th>affect</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>york city</th>\n",
       "      <th>yosemite</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  access  accident  actually  add  add stress  adult  adults  \\\n",
       "0        0     0       0         0         0    0           0      0       0   \n",
       "1        0     1       0         0         0    0           0      0       0   \n",
       "2        0     0       0         0         0    0           0      0       0   \n",
       "3        1     0       1         0         0    0           0      0       0   \n",
       "4        2     1       0         0         0    0           0      0       0   \n",
       "\n",
       "   affect  ...  written  wrong  year  years  yes  york  york city  yosemite  \\\n",
       "0       0  ...        0      0     0      0    0     0          0         0   \n",
       "1       0  ...        0      0     0      0    0     0          0         0   \n",
       "2       0  ...        0      1     0      0    0     0          0         0   \n",
       "3       0  ...        0      0     0      0    0     0          0         0   \n",
       "4       0  ...        0      0     0      0    0     0          0         0   \n",
       "\n",
       "   young  younger  \n",
       "0      0        0  \n",
       "1      0        0  \n",
       "2      0        0  \n",
       "3      0        0  \n",
       "4      0        0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X_cv array back to a DataFrame with meaningful column names\n",
    "X_cv = pd.DataFrame(X_cv, columns=feature_names)\n",
    "\n",
    "# Display the DataFrame\n",
    "X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b587b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>york city</th>\n",
       "      <th>yosemite</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>179</td>\n",
       "      <td>118</td>\n",
       "      <td>935</td>\n",
       "      <td>5.223464</td>\n",
       "      <td>71</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>235</td>\n",
       "      <td>141</td>\n",
       "      <td>1249</td>\n",
       "      <td>5.314894</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>105</td>\n",
       "      <td>816</td>\n",
       "      <td>5.551020</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>283</td>\n",
       "      <td>186</td>\n",
       "      <td>1678</td>\n",
       "      <td>5.929329</td>\n",
       "      <td>141</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>258</td>\n",
       "      <td>148</td>\n",
       "      <td>1391</td>\n",
       "      <td>5.391473</td>\n",
       "      <td>118</td>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_count  word_count  unique_word_count  character_count  \\\n",
       "0              16         179                118              935   \n",
       "1              17         235                141             1249   \n",
       "2              14         147                105              816   \n",
       "3              26         283                186             1678   \n",
       "4              30         258                148             1391   \n",
       "\n",
       "   average_word_length  noun_count  verb_count  adj_count  adverb_count  \\\n",
       "0             5.223464          71          43         25            15   \n",
       "1             5.314894          98          63         25            13   \n",
       "2             5.551020          73          35         23             3   \n",
       "3             5.929329         141          61         37            14   \n",
       "4             5.391473         118          49         24            16   \n",
       "\n",
       "   pronoun_count  ...  written  wrong  year  years  yes  york  york city  \\\n",
       "0             13  ...        0      0     0      0    0     0          0   \n",
       "1             15  ...        0      0     0      0    0     0          0   \n",
       "2              3  ...        0      1     0      0    0     0          0   \n",
       "3              5  ...        0      0     0      0    0     0          0   \n",
       "4              5  ...        0      0     0      0    0     0          0   \n",
       "\n",
       "   yosemite  young  younger  \n",
       "0         0      0        0  \n",
       "1         0      0        0  \n",
       "2         0      0        0  \n",
       "3         0      0        0  \n",
       "4         0      0        0  \n",
       "\n",
       "[5 rows x 1014 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine processed features and bag-of-words (n-grams) representation to create the feature matrix for modeling.\n",
    "\n",
    "X1 = pd.concat([df.iloc[:, 5:], X_cv], axis = 1)\n",
    "y = df['grade']\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4d0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets.\n",
    "train_X, test_X, train_y, test_y = train_test_split(X1, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17e0f4",
   "metadata": {},
   "source": [
    "SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2580df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 53.82024856700573\n",
      "Mean Absolute Error: 3.8057984530971285\n",
      "Root Mean Squared Error: 7.336228497464193\n",
      "Cohen's Kappa Score: 0.5373751259941353\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train an SVM regression model, evaluate using multiple metrics, and visualize the results.\n",
    "\n",
    "svm = SVR(C=1.0, epsilon=0.2)\n",
    "svm.fit(train_X, train_y)\n",
    "\n",
    "# Save the SVM model to a file\n",
    "joblib.dump(svm, 'Models/svm_model.pkl')\n",
    "\n",
    "# Load the SVM model from the file\n",
    "loaded_svm = joblib.load('Models/svm_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "pred_y = loaded_svm.predict(test_X)\n",
    "\n",
    "\n",
    "# Evaluate using MAE, MSE, RMSE, and Cohen's Kappa\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "mae = mean_absolute_error(test_y, pred_y)\n",
    "rmse = np.sqrt(mse)\n",
    "kappa = cohen_kappa_score(test_y, np.around(pred_y), weights='quadratic')\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Cohen's Kappa Score:\", kappa)\n",
    "\n",
    "# Visualize results\n",
    "results = {\n",
    "    \"MSE\": mse,\n",
    "    \"MAE\": mae,\n",
    "    \"RMSE\": rmse,\n",
    "    \"Kappa\": kappa\n",
    "}\n",
    "visualize_results(results, f\" SVM Results using Count Vectorization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db25d6",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb340578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.760759472892941\n",
      "Mean Absolute Error: 1.0631833633016525\n",
      "Root Mean Squared Error: 2.181916467899938\n",
      "Cohen's Kappa Score: 0.9691670940684024\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train a Random Forest regression model, evaluate using multiple metrics, and visualize the results.\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "# Save the RF model to a file\n",
    "joblib.dump(rf, 'Models/rf_model.pkl')\n",
    "\n",
    "# Load the RF model from the file\n",
    "loaded_rf = joblib.load('Models/rf_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "pred_y = loaded_rf.predict(test_X)\n",
    "\n",
    "# Evaluate using MAE, MSE, RMSE, and Cohen's Kappa\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "mae = mean_absolute_error(test_y, pred_y)\n",
    "rmse = np.sqrt(mse)\n",
    "kappa = cohen_kappa_score(test_y, np.around(pred_y), weights='quadratic')\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Cohen's Kappa Score:\", kappa)\n",
    "\n",
    "# Visualize results\n",
    "results = {\n",
    "    \"MSE\": mse,\n",
    "    \"MAE\": mae,\n",
    "    \"RMSE\": rmse,\n",
    "    \"Kappa\": kappa\n",
    "}\n",
    "visualize_results(results, f\" Random Forest Results using Count Vectorization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75768814",
   "metadata": {},
   "source": [
    "Contribution 2: Evaluation of Deep Learning Models on Contextual Features of Essays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ef972",
   "metadata": {},
   "source": [
    "WORD EMBEDDING: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3dc5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to generate feature vectors for words and essays using a Word2Vec model.\n",
    "\n",
    "def generate_feature_vector(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Generate a feature vector for a list of words using the Word2Vec model.\n",
    "\n",
    "    Args:\n",
    "        words (list): A list of words.\n",
    "        model (Word2Vec): The Word2Vec model for word embeddings.\n",
    "        num_features (int): The number of features in the word embeddings.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The feature vector for the input list of words.\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros(num_features, dtype=\"float32\")\n",
    "    num_words = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            num_words += 1\n",
    "            feature_vec = np.add(feature_vec, model.wv[word])\n",
    "\n",
    "    if num_words > 0:\n",
    "        feature_vec /= num_words\n",
    "\n",
    "    return feature_vec\n",
    "\n",
    "def generate_average_feature_vectors(essays, model, num_features):\n",
    "    \"\"\"\n",
    "    Generate the average feature vectors for a list of essays using the Word2Vec model.\n",
    "\n",
    "    Args:\n",
    "        essays (list): A list of essays, where each essay is represented as a list of words.\n",
    "        model: The Word2Vec model used for feature extraction.\n",
    "        num_features (int): The number of features in the Word2Vec model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of average feature vectors for each essay in the input list.\n",
    "    \"\"\"\n",
    "    essay_feature_vecs = np.zeros((len(essays), num_features), dtype=\"float32\")\n",
    "    no_of_vec = 0\n",
    "\n",
    "    for essay in essays:\n",
    "        feature_vec = generate_feature_vector(essay, model, num_features)\n",
    "        essay_feature_vecs[no_of_vec] = feature_vec\n",
    "        no_of_vec += 1\n",
    "\n",
    "    return essay_feature_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d61b22",
   "metadata": {},
   "source": [
    "2-LAYER LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c54b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-Layer LSTM Model definition\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Define a 2-layer Long Short-Term Memory (LSTM) model for regression tasks.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Sequential: A Keras Sequential model representing the defined LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcbc38c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 18s 38ms/step - loss: 54.0128 - mae: 3.7394\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 29.7540 - mae: 2.5392\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 20.2280 - mae: 2.1977\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 15.0424 - mae: 1.9921\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 12.3555 - mae: 1.8401\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 10.5814 - mae: 1.7291\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 10.0064 - mae: 1.6965\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 9.5204 - mae: 1.6386\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 9.1127 - mae: 1.6024\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 5s 34ms/step - loss: 8.6897 - mae: 1.5808\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.4679 - mae: 1.5511\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 8.0810 - mae: 1.5236\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.6811 - mae: 1.4924\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.7860 - mae: 1.4890\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 7.4715 - mae: 1.4737\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 7.6032 - mae: 1.4757\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.6400 - mae: 1.4736\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 7.5223 - mae: 1.4468\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 7.5994 - mae: 1.4468\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 7.4740 - mae: 1.4579\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.2419 - mae: 1.4232\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 7.0766 - mae: 1.4104\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 7.2863 - mae: 1.4144\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.6149 - mae: 1.3710\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.9551 - mae: 1.4001\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 6.9648 - mae: 1.3973\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.8241 - mae: 1.3841\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.8055 - mae: 1.3725\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.0064 - mae: 1.3873\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.8003 - mae: 1.3832\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.8660 - mae: 1.3761\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.5898 - mae: 1.3547\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 6.1168 - mae: 1.3325\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.4972 - mae: 1.3491\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.8233 - mae: 1.3620\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.2055 - mae: 1.3283\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 6.1696 - mae: 1.3348\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.2501 - mae: 1.3197\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.4703 - mae: 1.3318\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.3096 - mae: 1.3394\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 5.9229 - mae: 1.3147\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 6.0368 - mae: 1.3069\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.3247 - mae: 1.3344\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.1673 - mae: 1.3200\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 6.1253 - mae: 1.3223\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 5.9703 - mae: 1.3059\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.0860 - mae: 1.3124\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 5.8844 - mae: 1.3012\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 5s 34ms/step - loss: 5.8668 - mae: 1.2868\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 5.7046 - mae: 1.2783\n",
      "82/82 [==============================] - 2s 6ms/step\n",
      "Fold 1 MSE: 4.6074730354391376\n",
      "Fold 1 RMSE: 2.1465025123300316\n",
      "Fold 1 MAE: 1.1067026194144838\n",
      "Fold 1 Kappa Score: 0.971662290841407\n",
      "\n",
      "Training Fold 2\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 12s 37ms/step - loss: 53.4489 - mae: 3.7729\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 29.2886 - mae: 2.5433\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 20.6642 - mae: 2.2328\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 14.7790 - mae: 1.9857\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 12.3582 - mae: 1.8313\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 10.5486 - mae: 1.7216\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 9.5634 - mae: 1.6659\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 9.0809 - mae: 1.6309\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 9.0861 - mae: 1.6096\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 8.8877 - mae: 1.5857\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 4s 28ms/step - loss: 8.1932 - mae: 1.5337\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 8.5323 - mae: 1.5585\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 8.5800 - mae: 1.5319\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 7.9490 - mae: 1.4989\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 7.6828 - mae: 1.4788\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.6846 - mae: 1.4809\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.4863 - mae: 1.4588\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.7223 - mae: 1.4766\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.2918 - mae: 1.4299\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.8736 - mae: 1.4159\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 6.9713 - mae: 1.4174\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 7.1681 - mae: 1.4359\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 7.2107 - mae: 1.4106\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 7.1294 - mae: 1.4010\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.8522 - mae: 1.3941\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.7081 - mae: 1.3895\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 6.9327 - mae: 1.3874\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.6227 - mae: 1.3762\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 6.6951 - mae: 1.3770\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 6.9767 - mae: 1.3769\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 6.6846 - mae: 1.3709\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 6.6343 - mae: 1.3612\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 6.4690 - mae: 1.3571\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 4s 25ms/step - loss: 6.5141 - mae: 1.3468\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 6.2759 - mae: 1.3417\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 6.2955 - mae: 1.3387\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 6.3813 - mae: 1.3436\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 6.0567 - mae: 1.3215\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 6.3369 - mae: 1.3365\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 6.1446 - mae: 1.3186\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 6.1621 - mae: 1.3287\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 6.0309 - mae: 1.3126\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 6.3318 - mae: 1.3234\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 5.9879 - mae: 1.3160\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.1231 - mae: 1.3132\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 5.8430 - mae: 1.2876\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 5.6714 - mae: 1.2755\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 5.8626 - mae: 1.3076\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.0945 - mae: 1.2979\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 5.6797 - mae: 1.2724\n",
      "82/82 [==============================] - 2s 6ms/step\n",
      "Fold 2 MSE: 5.41888246628131\n",
      "Fold 2 RMSE: 2.3278493220741994\n",
      "Fold 2 MAE: 1.1483622350674374\n",
      "Fold 2 Kappa Score: 0.966465874303621\n",
      "\n",
      "Training Fold 3\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 11s 34ms/step - loss: 52.6420 - mae: 3.7717\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 29.2429 - mae: 2.5660\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 20.6838 - mae: 2.2518\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 15.3205 - mae: 2.0051\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 11.7736 - mae: 1.8160\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 10.4374 - mae: 1.7264\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 9.4290 - mae: 1.6687\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 9.4310 - mae: 1.6343\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 8.6994 - mae: 1.5985\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 8.8233 - mae: 1.5621\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 8.0216 - mae: 1.5147\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 8.0305 - mae: 1.5182\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.6148 - mae: 1.5011\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 8.3316 - mae: 1.5151\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.5418 - mae: 1.4700\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 7.5738 - mae: 1.4814\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 7.5253 - mae: 1.4429\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.6843 - mae: 1.4651\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.1863 - mae: 1.4206\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.3939 - mae: 1.4325\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.2941 - mae: 1.4253\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.9393 - mae: 1.3974\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 7.0228 - mae: 1.3993\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.0435 - mae: 1.3983\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 9s 58ms/step - loss: 6.7255 - mae: 1.3875\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 6.9038 - mae: 1.3783\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 6.8290 - mae: 1.3925\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 6.6209 - mae: 1.3780\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.8216 - mae: 1.3735\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 5s 34ms/step - loss: 6.3953 - mae: 1.3566\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 6.4995 - mae: 1.3622\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 6.3725 - mae: 1.3396\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 6.2020 - mae: 1.3227\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 6s 36ms/step - loss: 6.4668 - mae: 1.3516\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.2643 - mae: 1.3245\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.0867 - mae: 1.3178\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 5.9200 - mae: 1.2973\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 5.8896 - mae: 1.3060\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 5s 34ms/step - loss: 6.1167 - mae: 1.3125\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.0062 - mae: 1.3008\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 5.8603 - mae: 1.2976\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.1031 - mae: 1.3154\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 5.7108 - mae: 1.2792\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.0392 - mae: 1.3023\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.0594 - mae: 1.3119\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 5.7085 - mae: 1.2815\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.0549 - mae: 1.2993\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 5.6694 - mae: 1.2711\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 5.8142 - mae: 1.2940\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 5.6592 - mae: 1.2841\n",
      "82/82 [==============================] - 1s 5ms/step\n",
      "Fold 3 MSE: 5.051637764932563\n",
      "Fold 3 RMSE: 2.247584873799555\n",
      "Fold 3 MAE: 1.139499036608863\n",
      "Fold 3 Kappa Score: 0.9680129004453628\n",
      "\n",
      "Training Fold 4\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 13s 31ms/step - loss: 54.1920 - mae: 3.8958\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 30.1313 - mae: 2.6462\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 21.0962 - mae: 2.2667\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 14.9461 - mae: 1.9902\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 12.7398 - mae: 1.8763\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 10.3952 - mae: 1.7429\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 9.9666 - mae: 1.6895\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 9.5062 - mae: 1.6604\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 9.3986 - mae: 1.6324\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 8.7814 - mae: 1.5785\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 8.4006 - mae: 1.5519\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 8.5481 - mae: 1.5527\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 8.1794 - mae: 1.5151\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 8.0762 - mae: 1.5147\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 7.7197 - mae: 1.4967\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 7.3328 - mae: 1.4636\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 7.9243 - mae: 1.4780\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 7.5739 - mae: 1.4519\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 7.6510 - mae: 1.4608\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 7.4357 - mae: 1.4554\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 6.9964 - mae: 1.4249\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 7.2164 - mae: 1.4159\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.5887 - mae: 1.4444\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 7.1516 - mae: 1.4156\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.2305 - mae: 1.4195\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.1407 - mae: 1.4060\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 6.8725 - mae: 1.3922\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 6.4226 - mae: 1.3684\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 6.6274 - mae: 1.3760\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 6.5729 - mae: 1.3564\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 6.7551 - mae: 1.3714\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 6.2287 - mae: 1.3401\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 6.6654 - mae: 1.3714\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.1580 - mae: 1.3199\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 6.3307 - mae: 1.3525\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.7067 - mae: 1.3670\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 6.3645 - mae: 1.3370\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.1122 - mae: 1.3190\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 6.4167 - mae: 1.3273\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.1415 - mae: 1.3335\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.3146 - mae: 1.3384\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 6.1947 - mae: 1.3179\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.0603 - mae: 1.3094\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.1444 - mae: 1.3122\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 5.8565 - mae: 1.2952\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 5.8878 - mae: 1.2979\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.2868 - mae: 1.3260\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.1848 - mae: 1.3148\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 5.9472 - mae: 1.2995\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 5.9060 - mae: 1.3061\n",
      "82/82 [==============================] - 1s 5ms/step\n",
      "Fold 4 MSE: 4.607707129094412\n",
      "Fold 4 RMSE: 2.146557040726943\n",
      "Fold 4 MAE: 1.115606936416185\n",
      "Fold 4 Kappa Score: 0.9716639257261426\n",
      "\n",
      "Training Fold 5\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 1, 300)            721200    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 12s 31ms/step - loss: 53.2198 - mae: 3.7638\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 29.5805 - mae: 2.5539\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 5s 34ms/step - loss: 20.9627 - mae: 2.2726\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 15.4352 - mae: 2.0210\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 12.5355 - mae: 1.8603\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 10.7500 - mae: 1.7494\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 10.2374 - mae: 1.6913\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 9.5663 - mae: 1.6353\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 9.4099 - mae: 1.6200\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 8.7070 - mae: 1.5822\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 8.2905 - mae: 1.5510\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 8.5318 - mae: 1.5389\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 8.6222 - mae: 1.5435\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.9584 - mae: 1.4887\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.8889 - mae: 1.4940\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.9609 - mae: 1.4856\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.4282 - mae: 1.4559\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.6142 - mae: 1.4619\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.6176 - mae: 1.4493\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.1510 - mae: 1.4308\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.5615 - mae: 1.4282\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.2389 - mae: 1.4294\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.1750 - mae: 1.4167\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.9939 - mae: 1.3917\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.0364 - mae: 1.3958\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.6404 - mae: 1.3652\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.6957 - mae: 1.3708\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 6.5817 - mae: 1.3814\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 6.9367 - mae: 1.3914\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 6.6473 - mae: 1.3706\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.2823 - mae: 1.3427\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 6.3141 - mae: 1.3480\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.6338 - mae: 1.3527\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.5622 - mae: 1.3603\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.3638 - mae: 1.3447\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.2083 - mae: 1.3283\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.2855 - mae: 1.3340\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.1905 - mae: 1.3302\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.2338 - mae: 1.3165\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 5.8326 - mae: 1.2968\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.0905 - mae: 1.3120\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 6.1234 - mae: 1.3284\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 6.1364 - mae: 1.3081\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 5.7769 - mae: 1.2983\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 5.8531 - mae: 1.3039\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 5.6177 - mae: 1.2902\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 6.2888 - mae: 1.3121\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 5.9767 - mae: 1.3002\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 5.5913 - mae: 1.2774\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 5.6576 - mae: 1.2875\n",
      "82/82 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yabio\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 MSE: 4.633911368015414\n",
      "Fold 5 RMSE: 2.152652170699069\n",
      "Fold 5 MAE: 1.0701348747591521\n",
      "Fold 5 Kappa Score: 0.9697319774806\n"
     ]
    }
   ],
   "source": [
    "# 2-Layer LSTM Model Training and Testing\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []  # List to store Mean Squared Error (MSE) scores\n",
    "rmse_scores = []  # List to store Root Mean Squared Error (RMSE) scores\n",
    "mae_scores = []  # List to store Mean Absolute Error (MAE) scores\n",
    "kappa_scores = []  # List to store Cohen's Kappa scores\n",
    "\n",
    "count = 1\n",
    "for trainkf, testkf in kf.split(df):\n",
    "    print(\"\\nTraining Fold {}\\n\".format(count))\n",
    "    X_train, X_test, y_train, y_test = df.iloc[trainkf], df.iloc[testkf], y.iloc[trainkf], y.iloc[testkf]\n",
    "        \n",
    "    # Tokenize essays for training and testing data\n",
    "    train_essays = [essay.split() for essay in X_train['token_essay']]\n",
    "    test_essays = [essay.split() for essay in X_test['token_essay']]\n",
    "                 \n",
    "    # Initializing variables for Word2Vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    \n",
    "    # Train Word2Vec model on training essays\n",
    "    model_lstm = Word2Vec(train_essays, \n",
    "                     workers=num_workers, \n",
    "                     vector_size=num_features, \n",
    "                     min_count=min_word_count, \n",
    "                     window=context, \n",
    "                     sample=downsampling)\n",
    "\n",
    "    # Save the Word2Vec model\n",
    "    model_lstm.wv.save_word2vec_format('Models/word2vecmodel_lstm2.bin', binary=True)\n",
    "\n",
    "    # Generate average feature vectors for training and testing essays\n",
    "    training_vectors = generate_average_feature_vectors(train_essays, model_lstm, num_features)\n",
    "    testing_vectors = generate_average_feature_vectors(test_essays, model_lstm, num_features)\n",
    "\n",
    "    training_vectors = np.array(training_vectors)\n",
    "    testing_vectors = np.array(testing_vectors)\n",
    "    \n",
    "    # Reshape train and test vectors to 3 dimensions. (1 represents one timestep)\n",
    "    training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "    testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "    \n",
    "    # Create and train the 2-Layer LSTM model\n",
    "    lstm_model2 = get_model()\n",
    "    lstm_model2.fit(training_vectors, y_train, batch_size=64, epochs=50)\n",
    "    \n",
    "    y_pred = lstm_model2.predict(testing_vectors)\n",
    "    \n",
    "    # Save the model on the last fold\n",
    "    if count == 5:\n",
    "        lstm_model2.save('Models/model_lstm2.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)    \n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
    "    \n",
    "    print(\"Fold {} MSE: {}\".format(count, mse))\n",
    "    print(\"Fold {} RMSE: {}\".format(count, rmse))\n",
    "    print(\"Fold {} MAE: {}\".format(count, mae))\n",
    "    print(\"Fold {} Kappa Score: {}\".format(count, kappa))\n",
    "    \n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35ade3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE for LSTM 2-layers:  4.863922352752568\n",
      "Average RMSE for LSTM 2-layers:  2.2042291839259596\n",
      "Average MAE for LSTM 2-layers:  1.1160611404532244\n",
      "Average Kappa for LSTM 2-layers:  0.9695073937594266\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2-Layer LSTM Model Evaluation\n",
    "print(\"Average MSE for LSTM 2-layers: \", np.mean(mse_scores))\n",
    "print(\"Average RMSE for LSTM 2-layers: \", np.mean(rmse_scores))\n",
    "print(\"Average MAE for LSTM 2-layers: \", np.mean(mae_scores))\n",
    "print(\"Average Kappa for LSTM 2-layers: \", np.mean(kappa_scores))\n",
    "\n",
    "# Visualize results\n",
    "results = {\n",
    "    \"Average MSE\": np.mean(mse_scores),\n",
    "    \"Average MAE\": np.mean(mae_scores),\n",
    "    \"Average RMSE\": np.mean(rmse_scores),\n",
    "    \"Average Kappa\": np.mean(kappa_scores)\n",
    "}\n",
    "visualize_results(results, f\" Results using LSTM 2-layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff28d2",
   "metadata": {},
   "source": [
    "3-LAYER LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f77b13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-Layer LSTM Model definition\n",
    "def get_model3():\n",
    "    \"\"\"\n",
    "    Define a 3-layer Long Short-Term Memory (LSTM) model for regression tasks.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Sequential: A Keras Sequential model representing the defined LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4, return_sequences=True))\n",
    "    model.add(LSTM(32, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e55f198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 1, 64)             93440     \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 827089 (3.16 MB)\n",
      "Trainable params: 827089 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 16s 34ms/step - loss: 70.0455 - mae: 4.2013\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 46.8449 - mae: 3.0230\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 34.6921 - mae: 2.5692\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 27.9623 - mae: 2.3295\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 22.6606 - mae: 2.1526\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 18.0062 - mae: 1.9836\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 15.0996 - mae: 1.8705\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 12.8193 - mae: 1.7506\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 11.4767 - mae: 1.6675\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 10.3982 - mae: 1.6194\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.6994 - mae: 1.5776\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 9.2202 - mae: 1.5358\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 9.7702 - mae: 1.5590\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 9.2084 - mae: 1.5406\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 8.8234 - mae: 1.5012\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 9.1220 - mae: 1.5226\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 8.3530 - mae: 1.4803\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 8.4212 - mae: 1.4792\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 8.5217 - mae: 1.4819\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 8.0890 - mae: 1.4574\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 8.7021 - mae: 1.4873\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.9123 - mae: 1.4428\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.8278 - mae: 1.4201\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.9819 - mae: 1.4443\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.5084 - mae: 1.4018\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.8465 - mae: 1.4215\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.5888 - mae: 1.4121\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.5214 - mae: 1.3991\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.2497 - mae: 1.3898\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.5538 - mae: 1.3918\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.0904 - mae: 1.3856\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.1636 - mae: 1.3754\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 7.0601 - mae: 1.3635\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.6307 - mae: 1.3967\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.4735 - mae: 1.3893\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.0358 - mae: 1.3623\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.8537 - mae: 1.3503\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6.6702 - mae: 1.3364\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.9870 - mae: 1.3487\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 7.0789 - mae: 1.3593\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 5s 34ms/step - loss: 6.5233 - mae: 1.3202\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.8912 - mae: 1.3417\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.6322 - mae: 1.3242\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 6.6613 - mae: 1.3338\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.3898 - mae: 1.3121\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 6.5453 - mae: 1.3409\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 6.3616 - mae: 1.3137\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.6473 - mae: 1.3350\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.4523 - mae: 1.3153\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.0730 - mae: 1.3382\n",
      "82/82 [==============================] - 2s 6ms/step\n",
      "Fold 1 MSE: 5.127503852080123\n",
      "Fold 1 RMSE: 2.2643992254194316\n",
      "Fold 1 MAE: 1.1213405238828968\n",
      "Fold 1 Kappa Score: 0.965585837963628\n",
      "\n",
      "Training Fold 2\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 1, 64)             93440     \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 827089 (3.16 MB)\n",
      "Trainable params: 827089 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 15s 36ms/step - loss: 72.3011 - mae: 4.2109\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 48.6889 - mae: 3.0880\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 36.6112 - mae: 2.5874\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 29.4057 - mae: 2.3749\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 23.6956 - mae: 2.1924\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 19.0425 - mae: 2.0145\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 15.9375 - mae: 1.9048\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 13.9411 - mae: 1.7876\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 11.8884 - mae: 1.7036\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 11.4303 - mae: 1.6663\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 10.4092 - mae: 1.6082\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 9.6134 - mae: 1.5545\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 9.3074 - mae: 1.5481\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 9.4852 - mae: 1.5411\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 8.9357 - mae: 1.5100\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 8.8747 - mae: 1.5056\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 8.7193 - mae: 1.5045\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 8.5655 - mae: 1.4745\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 9.1716 - mae: 1.5109\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 8.5481 - mae: 1.4772\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 8.8597 - mae: 1.4818\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 8.4640 - mae: 1.4666\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.7645 - mae: 1.4239\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.9693 - mae: 1.4446\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 8.7879 - mae: 1.4533\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.6504 - mae: 1.4168\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 8.0416 - mae: 1.4515\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.6117 - mae: 1.4142\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 8.1106 - mae: 1.4282\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.9168 - mae: 1.4122\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.5896 - mae: 1.3987\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.6844 - mae: 1.4086\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.8991 - mae: 1.4000\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.7282 - mae: 1.4022\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.5818 - mae: 1.3778\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 7.3737 - mae: 1.3767\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.3075 - mae: 1.3722\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 7.3679 - mae: 1.3774\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 7.2327 - mae: 1.3604\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 7.2096 - mae: 1.3699\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.0593 - mae: 1.3720\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 7.1710 - mae: 1.3576\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.2008 - mae: 1.3578\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 7.3480 - mae: 1.3772\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 7.1957 - mae: 1.3614\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 6.9111 - mae: 1.3578\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 6.8964 - mae: 1.3363\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.7314 - mae: 1.3374\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.2076 - mae: 1.3733\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.9713 - mae: 1.3476\n",
      "82/82 [==============================] - 3s 7ms/step\n",
      "Fold 2 MSE: 4.645857418111754\n",
      "Fold 2 RMSE: 2.1554251130836706\n",
      "Fold 2 MAE: 1.1013487475915222\n",
      "Fold 2 Kappa Score: 0.9698219348840291\n",
      "\n",
      "Training Fold 3\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 1, 64)             93440     \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 827089 (3.16 MB)\n",
      "Trainable params: 827089 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 26s 49ms/step - loss: 71.1197 - mae: 4.1665\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 47.5958 - mae: 3.0748\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 36.0765 - mae: 2.6052\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 28.6436 - mae: 2.3581\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 22.9731 - mae: 2.1828\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 18.9922 - mae: 2.0288\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 16.1641 - mae: 1.9263\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 13.3695 - mae: 1.7892\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 11.8025 - mae: 1.7067\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 10.4051 - mae: 1.6283\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 10.3952 - mae: 1.6112\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 9.2983 - mae: 1.5647\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 9.4157 - mae: 1.5660\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 9.4338 - mae: 1.5443\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 9.1442 - mae: 1.5331\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 8.7545 - mae: 1.4955\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 8.4183 - mae: 1.4720\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 8.7236 - mae: 1.4984\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 9.0333 - mae: 1.5122\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 8.4886 - mae: 1.4736\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 8.5542 - mae: 1.4712\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 8.4123 - mae: 1.4701\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 8.1247 - mae: 1.4651\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.7702 - mae: 1.4314\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 8.0772 - mae: 1.4466\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.9624 - mae: 1.4270\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.9941 - mae: 1.4258\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.5495 - mae: 1.4043\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 6s 38ms/step - loss: 8.0692 - mae: 1.4286\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.4491 - mae: 1.3957\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.4489 - mae: 1.4062\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 7.7053 - mae: 1.4100\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.4527 - mae: 1.3932\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 7.3325 - mae: 1.4049\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.1431 - mae: 1.3829\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.3382 - mae: 1.3885\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.4652 - mae: 1.3990\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.1875 - mae: 1.3676\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.8338 - mae: 1.3649\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 7.1226 - mae: 1.3726\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.8065 - mae: 1.3487\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.7867 - mae: 1.3614\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.1571 - mae: 1.3682\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 6.8426 - mae: 1.3455\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.7563 - mae: 1.3478\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.4685 - mae: 1.3255\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 6.7364 - mae: 1.3434\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.7667 - mae: 1.3398\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.8761 - mae: 1.3416\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 6.2106 - mae: 1.3096\n",
      "82/82 [==============================] - 3s 8ms/step\n",
      "Fold 3 MSE: 4.863969171483622\n",
      "Fold 3 RMSE: 2.205440811149468\n",
      "Fold 3 MAE: 1.1576107899807322\n",
      "Fold 3 Kappa Score: 0.9714317682938828\n",
      "\n",
      "Training Fold 4\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 1, 64)             93440     \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 827089 (3.16 MB)\n",
      "Trainable params: 827089 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 18s 37ms/step - loss: 76.4473 - mae: 4.3614\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 52.1549 - mae: 3.2014\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 39.3851 - mae: 2.7185\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 30.3565 - mae: 2.4050\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 24.7401 - mae: 2.2292\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 20.2592 - mae: 2.0739\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 16.5523 - mae: 1.9252\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 14.1530 - mae: 1.8113\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 12.3329 - mae: 1.7336\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 10.3939 - mae: 1.6203\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 10.3126 - mae: 1.6004\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 9.9553 - mae: 1.5790\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 9.4029 - mae: 1.5450\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.9927 - mae: 1.5651\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 8.9721 - mae: 1.5134\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 8.7790 - mae: 1.5011\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 8.9991 - mae: 1.5228\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.8915 - mae: 1.5085\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.6852 - mae: 1.4799\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 9.0522 - mae: 1.5005\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 8.1345 - mae: 1.4528\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 8.1022 - mae: 1.4469\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 8.4542 - mae: 1.4514\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 8.2009 - mae: 1.4452\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 8.2631 - mae: 1.4569\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 8.0084 - mae: 1.4358\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 8.1387 - mae: 1.4288\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 8.3655 - mae: 1.4565\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 8.0764 - mae: 1.4263\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7.5077 - mae: 1.3974\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 7.8353 - mae: 1.4135\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.8051 - mae: 1.4067\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 7.3467 - mae: 1.3876\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 7.5726 - mae: 1.3918\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.5286 - mae: 1.3948\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.3161 - mae: 1.3749\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.8561 - mae: 1.3565\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.2690 - mae: 1.3726\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.0600 - mae: 1.3672\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 6.9316 - mae: 1.3578\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.0914 - mae: 1.3520\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 6.6105 - mae: 1.3375\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 7.0965 - mae: 1.3472\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.0126 - mae: 1.3465\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 6.9776 - mae: 1.3450\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.9095 - mae: 1.3564\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 7.0542 - mae: 1.3594\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 6.8352 - mae: 1.3366\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 6.6081 - mae: 1.3275\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.3546 - mae: 1.3049\n",
      "82/82 [==============================] - 2s 6ms/step\n",
      "Fold 4 MSE: 4.5098265895953755\n",
      "Fold 4 RMSE: 2.123635229881859\n",
      "Fold 4 MAE: 1.092485549132948\n",
      "Fold 4 Kappa Score: 0.9721790244327434\n",
      "\n",
      "Training Fold 5\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 1, 64)             93440     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 827089 (3.16 MB)\n",
      "Trainable params: 827089 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 34s 42ms/step - loss: 71.2960 - mae: 4.2230\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 47.1219 - mae: 3.0457\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 35.1926 - mae: 2.5826\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 28.1205 - mae: 2.3344\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 23.3833 - mae: 2.1809\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 18.5091 - mae: 2.0111\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 15.5614 - mae: 1.8879\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 12.5822 - mae: 1.7487\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 11.4197 - mae: 1.6904\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 9.9671 - mae: 1.6139\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 10.0111 - mae: 1.5853\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 9.8883 - mae: 1.5849\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.8125 - mae: 1.5368\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 8.7016 - mae: 1.5213\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 8.7120 - mae: 1.4948\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 8.2629 - mae: 1.4802\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 11s 65ms/step - loss: 8.5875 - mae: 1.4867\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 8.6024 - mae: 1.4782\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.9101 - mae: 1.4557\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.1856 - mae: 1.4599\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 8.1822 - mae: 1.4438\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 8.2516 - mae: 1.4432\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 7.9441 - mae: 1.4392\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 8.1751 - mae: 1.4399\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.8801 - mae: 1.4266\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.1761 - mae: 1.4497\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.5655 - mae: 1.4115\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.8952 - mae: 1.4202\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 7.5249 - mae: 1.4122\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.1068 - mae: 1.3760\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.7201 - mae: 1.4024\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 7.0516 - mae: 1.3725\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.2998 - mae: 1.3893\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 7.5272 - mae: 1.3953\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.5959 - mae: 1.3912\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.1547 - mae: 1.3625\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.1683 - mae: 1.3685\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.7430 - mae: 1.3444\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 6.7201 - mae: 1.3395\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.1540 - mae: 1.3639\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 7.0012 - mae: 1.3614\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 6.9425 - mae: 1.3557\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 6.9633 - mae: 1.3542\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 6.7073 - mae: 1.3235\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.7075 - mae: 1.3235\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 6.8443 - mae: 1.3382\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 6.7614 - mae: 1.3386\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 6.7537 - mae: 1.3341\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 12s 73ms/step - loss: 6.5971 - mae: 1.3241\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 6.7280 - mae: 1.3308\n",
      "82/82 [==============================] - 4s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yabio\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 MSE: 5.788053949903661\n",
      "Fold 5 RMSE: 2.4058374737092407\n",
      "Fold 5 MAE: 1.140655105973025\n",
      "Fold 5 Kappa Score: 0.9626486452830391\n"
     ]
    }
   ],
   "source": [
    "# 3-Layer LSTM Model Training and Testing\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []  # List to store Mean Squared Error (MSE) scores\n",
    "rmse_scores = []  # List to store Root Mean Squared Error (RMSE) scores\n",
    "mae_scores = []  # List to store Mean Absolute Error (MAE) scores\n",
    "kappa_scores = []  # List to store Cohen's Kappa scores\n",
    "\n",
    "count = 1\n",
    "for trainkf, testkf in kf.split(df):\n",
    "    print(\"\\nTraining Fold {}\\n\".format(count))\n",
    "    X_train, X_test, y_train, y_test = df.iloc[trainkf], df.iloc[testkf], y.iloc[trainkf], y.iloc[testkf]\n",
    "        \n",
    "    # Tokenize essays for training and testing data\n",
    "    train_essays = [essay.split() for essay in X_train['token_essay']]\n",
    "    test_essays = [essay.split() for essay in X_test['token_essay']]\n",
    "                 \n",
    "    # Initializing variables for Word2Vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    \n",
    "    # Train Word2Vec model on training essays\n",
    "    model_lstm = Word2Vec(train_essays, \n",
    "                     workers=num_workers, \n",
    "                     vector_size=num_features, \n",
    "                     min_count=min_word_count, \n",
    "                     window=context, \n",
    "                     sample=downsampling)\n",
    "\n",
    "    # Save the Word2Vec model\n",
    "    model_lstm.wv.save_word2vec_format('Models/word2vecmodel_lstm3.bin', binary=True)\n",
    "\n",
    "    # Generate average feature vectors for training and testing essays\n",
    "    training_vectors = generate_average_feature_vectors(train_essays, model_lstm, num_features)\n",
    "    testing_vectors = generate_average_feature_vectors(test_essays, model_lstm, num_features)\n",
    "\n",
    "    training_vectors = np.array(training_vectors)\n",
    "    testing_vectors = np.array(testing_vectors)\n",
    "    \n",
    "    # Reshape train and test vectors to 3 dimensions. (1 represents one timestep)\n",
    "    training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "    testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "    \n",
    "    # Create and train the 3-Layer LSTM model\n",
    "    lstm_model3 = get_model3()\n",
    "    lstm_model3.fit(training_vectors, y_train, batch_size=64, epochs=50)\n",
    "    \n",
    "    y_pred = lstm_model3.predict(testing_vectors)\n",
    "    \n",
    "    # Save the model on the last fold\n",
    "    if count == 5:\n",
    "        lstm_model3.save('Models/model_lstm3.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)    \n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
    "    \n",
    "    print(\"Fold {} MSE: {}\".format(count, mse))\n",
    "    print(\"Fold {} RMSE: {}\".format(count, rmse))\n",
    "    print(\"Fold {} MAE: {}\".format(count, mae))\n",
    "    print(\"Fold {} Kappa Score: {}\".format(count, kappa))\n",
    "    \n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1b79a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE for LSTM 3-layers:  4.987042196234907\n",
      "Average RMSE for LSTM 3-layers:  2.230947570648734\n",
      "Average MAE for LSTM 3-layers:  1.1226881433122249\n",
      "Average Kappa for LSTM 3-layers:  0.9683334421714644\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3-Layer LSTM Model Evaluation\n",
    "print(\"Average MSE for LSTM 3-layers: \", np.mean(mse_scores))\n",
    "print(\"Average RMSE for LSTM 3-layers: \", np.mean(rmse_scores))\n",
    "print(\"Average MAE for LSTM 3-layers: \", np.mean(mae_scores))\n",
    "print(\"Average Kappa for LSTM 3-layers: \", np.mean(kappa_scores))\n",
    "\n",
    "\n",
    "# Visualize results\n",
    "results = {\n",
    "    \"Average MSE\": np.mean(mse_scores),\n",
    "    \"Average MAE\": np.mean(mae_scores),\n",
    "    \"Average RMSE\": np.mean(rmse_scores),\n",
    "    \"Average Kappa\": np.mean(kappa_scores)\n",
    "}\n",
    "visualize_results(results, f\" Results using LSTM 3-layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91de5c",
   "metadata": {},
   "source": [
    "4-LAYER LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50481b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-Layer LSTM Model definition\n",
    "\n",
    "def get_model4():\n",
    "    \"\"\"\n",
    "    Define a 4-layer Long Short-Term Memory (LSTM) model for regression tasks.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Sequential: A Keras Sequential model representing the defined LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(128, recurrent_dropout=0.4, return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4, return_sequences=True))\n",
    "    model.add(LSTM(32, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "840015c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_25 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 1, 128)            219648    \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1002705 (3.83 MB)\n",
      "Trainable params: 1002705 (3.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 21s 52ms/step - loss: 72.0124 - mae: 4.1733\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 48.9582 - mae: 3.1331\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 36.9703 - mae: 2.6632\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 29.5588 - mae: 2.4098\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 23.9093 - mae: 2.2360\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 19.3442 - mae: 2.0608\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 16.4039 - mae: 1.9440\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 14.2413 - mae: 1.8418\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 11.8005 - mae: 1.7075\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 10.9219 - mae: 1.6654\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 10.0108 - mae: 1.6053\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 10.3252 - mae: 1.6124\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 9.6210 - mae: 1.5664\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 9.6775 - mae: 1.5725\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 9.1269 - mae: 1.5450\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 8.5062 - mae: 1.5040\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 8.3337 - mae: 1.4861\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 8.5677 - mae: 1.4961\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 9.0346 - mae: 1.5117\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 8.6666 - mae: 1.4911\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.0669 - mae: 1.4421\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 8.5354 - mae: 1.4805\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.2540 - mae: 1.4555\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 8.4028 - mae: 1.4526\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 7.9930 - mae: 1.4308\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.3878 - mae: 1.4753\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.0450 - mae: 1.4436\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.8629 - mae: 1.4212\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 7.8089 - mae: 1.4220\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 7.9429 - mae: 1.4227\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.6649 - mae: 1.4168\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 8.1305 - mae: 1.4341\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.9498 - mae: 1.4356\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 7.8887 - mae: 1.4167\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.0567 - mae: 1.3776\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 7.5445 - mae: 1.4017\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.3871 - mae: 1.3811\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 7.3976 - mae: 1.3965\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.8534 - mae: 1.3783\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.1563 - mae: 1.3648\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.1211 - mae: 1.3765\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.1711 - mae: 1.3693\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 6.8317 - mae: 1.3522\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.1076 - mae: 1.3631\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.0703 - mae: 1.3655\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 6.9220 - mae: 1.3509\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 6.8009 - mae: 1.3461\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.2025 - mae: 1.3706\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 6.8846 - mae: 1.3525\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 6.7044 - mae: 1.3275\n",
      "82/82 [==============================] - 3s 11ms/step\n",
      "Fold 1 MSE: 5.36517719568567\n",
      "Fold 1 RMSE: 2.3162852146671553\n",
      "Fold 1 MAE: 1.1263482280431434\n",
      "Fold 1 Kappa Score: 0.9688920807192598\n",
      "\n",
      "Training Fold 2\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_29 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 1, 128)            219648    \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1002705 (3.83 MB)\n",
      "Trainable params: 1002705 (3.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 36s 53ms/step - loss: 72.4952 - mae: 4.2185\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 48.3018 - mae: 3.0958\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 36.3606 - mae: 2.6296\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 28.1792 - mae: 2.3496\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 23.8450 - mae: 2.2320\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 19.4597 - mae: 2.0648\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 15.6254 - mae: 1.9160\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 13.4785 - mae: 1.8199\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 11.5794 - mae: 1.6887\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 10.2272 - mae: 1.6253\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 9.8555 - mae: 1.5882\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 9.1452 - mae: 1.5416\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 8.9435 - mae: 1.5330\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 8.7458 - mae: 1.5248\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 9.0725 - mae: 1.5242\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 8.5213 - mae: 1.4852\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 8.1627 - mae: 1.4611\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 8.8901 - mae: 1.5009\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 8.5068 - mae: 1.4790\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 8.6686 - mae: 1.4775\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 7.8426 - mae: 1.4292\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 12s 71ms/step - loss: 7.9591 - mae: 1.4434\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 7.4280 - mae: 1.4172\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 7.6757 - mae: 1.4093\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 8.1198 - mae: 1.4307\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 7.5798 - mae: 1.4126\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 7.4560 - mae: 1.4012\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 7.3072 - mae: 1.3915\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 7.4865 - mae: 1.3988\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.7198 - mae: 1.4024\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 7.5157 - mae: 1.4020\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 7.4865 - mae: 1.3858\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.0704 - mae: 1.3818\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 7.6587 - mae: 1.4001\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 7.0417 - mae: 1.3632\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 11s 68ms/step - loss: 6.8268 - mae: 1.3511\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 14s 84ms/step - loss: 7.4976 - mae: 1.3866\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.0860 - mae: 1.3583\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.2950 - mae: 1.3634\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.0930 - mae: 1.3615\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.8346 - mae: 1.3392\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 6.8591 - mae: 1.3569\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.8727 - mae: 1.3399\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.8323 - mae: 1.3288\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 12s 72ms/step - loss: 6.6458 - mae: 1.3368\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 6.6537 - mae: 1.3282\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 6.6248 - mae: 1.3293\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 6.6373 - mae: 1.3268\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 6.3415 - mae: 1.3166\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 6.8925 - mae: 1.3305\n",
      "82/82 [==============================] - 4s 10ms/step\n",
      "Fold 2 MSE: 5.211560693641618\n",
      "Fold 2 RMSE: 2.282884292652963\n",
      "Fold 2 MAE: 1.1514450867052024\n",
      "Fold 2 Kappa Score: 0.9660278738273229\n",
      "\n",
      "Training Fold 3\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 1, 128)            219648    \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1002705 (3.83 MB)\n",
      "Trainable params: 1002705 (3.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 22s 47ms/step - loss: 77.0461 - mae: 4.3370\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 51.9602 - mae: 3.2248\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 40.1024 - mae: 2.7891\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 30.9154 - mae: 2.4607\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 24.9170 - mae: 2.2768\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 20.3415 - mae: 2.1056\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 16.5507 - mae: 1.9613\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 14.5239 - mae: 1.8343\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 12.1317 - mae: 1.7369\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 11.3334 - mae: 1.6711\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 9.9024 - mae: 1.6005\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 22s 132ms/step - loss: 9.4356 - mae: 1.5625\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 9.4891 - mae: 1.5593\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 9.6019 - mae: 1.5639\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 8.6203 - mae: 1.5100\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 8.7998 - mae: 1.5079\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 8.7163 - mae: 1.5000\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.1706 - mae: 1.4702\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 8.5049 - mae: 1.4777\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 8.1463 - mae: 1.4633\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 8.0771 - mae: 1.4496\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.2619 - mae: 1.4619\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 8.0054 - mae: 1.4419\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 7.9848 - mae: 1.4377\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 10s 63ms/step - loss: 7.5340 - mae: 1.4125\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 8.1797 - mae: 1.4439\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 7.9648 - mae: 1.4381\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 8.0422 - mae: 1.4386\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 7.5807 - mae: 1.4002\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.7506 - mae: 1.4147\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 8.2936 - mae: 1.4442\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.4828 - mae: 1.3989\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 7.0947 - mae: 1.3814\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.2124 - mae: 1.3800\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 7.1740 - mae: 1.3739\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 6.8686 - mae: 1.3514\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.3399 - mae: 1.3762\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.2639 - mae: 1.3800\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.2933 - mae: 1.3861\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 6.6587 - mae: 1.3413\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.0645 - mae: 1.3667\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 6.4593 - mae: 1.3422\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 6.7719 - mae: 1.3494\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 7.0565 - mae: 1.3501\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 6.7111 - mae: 1.3483\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 6.6973 - mae: 1.3334\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 6.7352 - mae: 1.3319\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 6.4390 - mae: 1.3278\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 6.2961 - mae: 1.3162\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 6.6993 - mae: 1.3389\n",
      "82/82 [==============================] - 4s 10ms/step\n",
      "Fold 3 MSE: 5.737186897880539\n",
      "Fold 3 RMSE: 2.39524255512475\n",
      "Fold 3 MAE: 1.1352601156069364\n",
      "Fold 3 Kappa Score: 0.9612248557841608\n",
      "\n",
      "Training Fold 4\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_37 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 1, 128)            219648    \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1002705 (3.83 MB)\n",
      "Trainable params: 1002705 (3.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 27s 46ms/step - loss: 71.5014 - mae: 4.1448\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 48.2024 - mae: 3.1086\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 37.1354 - mae: 2.6521\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 29.1779 - mae: 2.3948\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 23.4780 - mae: 2.1838\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 18.8987 - mae: 2.0395\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 16.1127 - mae: 1.8968\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 13.8837 - mae: 1.8035\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 11.9520 - mae: 1.7151\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 10.9408 - mae: 1.6662\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 10.0469 - mae: 1.5931\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.8954 - mae: 1.5847\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.5487 - mae: 1.5375\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.1459 - mae: 1.5304\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 9.2890 - mae: 1.5227\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.1221 - mae: 1.5273\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 8.4893 - mae: 1.4822\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 9.0831 - mae: 1.5102\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.3218 - mae: 1.4542\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 8.6482 - mae: 1.4697\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 8.2633 - mae: 1.4540\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 8.4863 - mae: 1.4769\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 8.1838 - mae: 1.4460\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 8.3127 - mae: 1.4623\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 8.7406 - mae: 1.4736\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 7.8857 - mae: 1.4234\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 8.0787 - mae: 1.4260\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 8.3355 - mae: 1.4458\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 9s 58ms/step - loss: 7.8956 - mae: 1.4091\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 8.0250 - mae: 1.4271\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 11s 70ms/step - loss: 7.8127 - mae: 1.4182\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 7.9638 - mae: 1.4069\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 8.0678 - mae: 1.4082\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 7.2979 - mae: 1.3839\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 7.9332 - mae: 1.4078\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.7111 - mae: 1.4061\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 7.2223 - mae: 1.3690\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 10s 64ms/step - loss: 7.9054 - mae: 1.3919\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 9s 58ms/step - loss: 7.3626 - mae: 1.3704\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 7.6070 - mae: 1.3895\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.9912 - mae: 1.3530\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 6.9508 - mae: 1.3567\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.9658 - mae: 1.3508\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.0154 - mae: 1.3481\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 7.0948 - mae: 1.3491\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 6.9437 - mae: 1.3485\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 6.9303 - mae: 1.3321\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 7.1959 - mae: 1.3479\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 6.3438 - mae: 1.3129\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 6.9733 - mae: 1.3498\n",
      "82/82 [==============================] - 2s 8ms/step\n",
      "Fold 4 MSE: 4.517533718689788\n",
      "Fold 4 RMSE: 2.125449062831144\n",
      "Fold 4 MAE: 1.144894026974952\n",
      "Fold 4 Kappa Score: 0.9711468692622094\n",
      "\n",
      "Training Fold 5\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_41 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 1, 128)            219648    \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 1, 64)             49408     \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1002705 (3.83 MB)\n",
      "Trainable params: 1002705 (3.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 50s 74ms/step - loss: 70.6113 - mae: 4.1818\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 47.7535 - mae: 3.0841\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 35.3481 - mae: 2.6043\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 28.3140 - mae: 2.3752\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 23.3309 - mae: 2.2133\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 18.4615 - mae: 2.0060\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 11s 65ms/step - loss: 15.9791 - mae: 1.9210\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 10s 58ms/step - loss: 13.2692 - mae: 1.7777\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 10s 64ms/step - loss: 12.1417 - mae: 1.7095\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 10.6514 - mae: 1.6552\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 12s 76ms/step - loss: 10.6308 - mae: 1.6071\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 13s 77ms/step - loss: 9.8580 - mae: 1.5880\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 13s 81ms/step - loss: 9.1705 - mae: 1.5473\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 15s 90ms/step - loss: 9.2367 - mae: 1.5406\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 12s 74ms/step - loss: 9.0570 - mae: 1.5239\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 11s 69ms/step - loss: 8.6274 - mae: 1.5064\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 11s 68ms/step - loss: 8.8785 - mae: 1.5106\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 11s 67ms/step - loss: 9.2015 - mae: 1.5224\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 11s 69ms/step - loss: 9.2279 - mae: 1.5051\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 8.5226 - mae: 1.4878\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 8.3631 - mae: 1.4711\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 8.6289 - mae: 1.4854\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 9s 58ms/step - loss: 8.0818 - mae: 1.4543\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 8.4333 - mae: 1.4572\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 8.3854 - mae: 1.4651\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 10s 59ms/step - loss: 8.0711 - mae: 1.4567\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 8.0575 - mae: 1.4454\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 8.1285 - mae: 1.4471\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 7.8735 - mae: 1.4301\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 7.6452 - mae: 1.4197\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 7.8392 - mae: 1.4124\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 7.4401 - mae: 1.4032\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 7.9535 - mae: 1.4337\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 7.0804 - mae: 1.3810\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 7.2672 - mae: 1.3847\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 7.6596 - mae: 1.4047\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 7.3150 - mae: 1.3799\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 11s 65ms/step - loss: 7.7451 - mae: 1.3954\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 6.9937 - mae: 1.3761\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 10s 61ms/step - loss: 7.2351 - mae: 1.3814\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 7.1896 - mae: 1.3852\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 6.9884 - mae: 1.3673\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 7.5437 - mae: 1.3714\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 7.0210 - mae: 1.3615\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 7.0004 - mae: 1.3473\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 6.8387 - mae: 1.3502\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 7.0696 - mae: 1.3632\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 7.0734 - mae: 1.3623\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 6.6275 - mae: 1.3442\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 6.6547 - mae: 1.3369\n",
      "82/82 [==============================] - 6s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yabio\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 MSE: 5.521387283236995\n",
      "Fold 5 RMSE: 2.3497632398258754\n",
      "Fold 5 MAE: 1.1606936416184972\n",
      "Fold 5 Kappa Score: 0.9615375890741408\n"
     ]
    }
   ],
   "source": [
    "# 4-Layer LSTM Model Training and Testing\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "mse_scores = []  # List to store Mean Squared Error (MSE) scores\n",
    "rmse_scores = []  # List to store Root Mean Squared Error (RMSE) scores\n",
    "mae_scores = []  # List to store Mean Absolute Error (MAE) scores\n",
    "kappa_scores = []  # List to store Cohen's Kappa scores\n",
    "\n",
    "count = 1\n",
    "for trainkf, testkf in kf.split(df):\n",
    "    print(\"\\nTraining Fold {}\\n\".format(count))\n",
    "    X_train, X_test, y_train, y_test = df.iloc[trainkf], df.iloc[testkf], y.iloc[trainkf], y.iloc[testkf]\n",
    "        \n",
    "    # Tokenize essays for training and testing data\n",
    "    train_essays = [essay.split() for essay in X_train['token_essay']]\n",
    "    test_essays = [essay.split() for essay in X_test['token_essay']]\n",
    "                 \n",
    "    # Initializing variables for Word2Vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    \n",
    "    # Train Word2Vec model on training essays\n",
    "    model_lstm = Word2Vec(train_essays, \n",
    "                     workers=num_workers, \n",
    "                     vector_size=num_features, \n",
    "                     min_count=min_word_count, \n",
    "                     window=context, \n",
    "                     sample=downsampling)\n",
    "\n",
    "    # Save the Word2Vec model\n",
    "    model_lstm.wv.save_word2vec_format('Models/word2vecmodel_lstm4.bin', binary=True)\n",
    "\n",
    "    # Generate average feature vectors for training and testing essays\n",
    "    training_vectors = generate_average_feature_vectors(train_essays, model_lstm, num_features)\n",
    "    testing_vectors = generate_average_feature_vectors(test_essays, model_lstm, num_features)\n",
    "\n",
    "    training_vectors = np.array(training_vectors)\n",
    "    testing_vectors = np.array(testing_vectors)\n",
    "    \n",
    "    # Reshape train and test vectors to 3 dimensions. (1 represents one timestep)\n",
    "    training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "    testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "    \n",
    "    # Create and train the 4-Layer LSTM model\n",
    "    lstm_model4 = get_model4()\n",
    "    lstm_model4.fit(training_vectors, y_train, batch_size=64, epochs=50)\n",
    "    \n",
    "    y_pred = lstm_model4.predict(testing_vectors)\n",
    "    \n",
    "    # Save the model on the last fold\n",
    "    if count == 5:\n",
    "        lstm_model4.save('Models/model_lstm4.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)    \n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
    "    \n",
    "    print(\"Fold {} MSE: {}\".format(count, mse))\n",
    "    print(\"Fold {} RMSE: {}\".format(count, rmse))\n",
    "    print(\"Fold {} MAE: {}\".format(count, mae))\n",
    "    print(\"Fold {} Kappa Score: {}\".format(count, kappa))\n",
    "    \n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f61260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE for LSTM 4-layers:  5.270569157826921\n",
      "Average RMSE for LSTM 4-layers:  2.2939248730203774\n",
      "Average MAE for LSTM 4-layers:  1.1437282197897463\n",
      "Average Kappa for LSTM 4-layers:  0.9657658537334187\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4-Layer LSTM Model Evaluation\n",
    "print(\"Average MSE for LSTM 4-layers: \", np.mean(mse_scores))\n",
    "print(\"Average RMSE for LSTM 4-layers: \", np.mean(rmse_scores))\n",
    "print(\"Average MAE for LSTM 4-layers: \", np.mean(mae_scores))\n",
    "print(\"Average Kappa for LSTM 4-layers: \", np.mean(kappa_scores))\n",
    "\n",
    "\n",
    "# Visualize results\n",
    "results = {\n",
    "    \"Average MSE\": np.mean(mse_scores),\n",
    "    \"Average MAE\": np.mean(mae_scores),\n",
    "    \"Average RMSE\": np.mean(rmse_scores),\n",
    "    \"Average Kappa\": np.mean(kappa_scores)\n",
    "}\n",
    "visualize_results(results, f\" Results using LSTM 4-layers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631307b",
   "metadata": {},
   "source": [
    "Contribution 3: Exploring the Effect of Grade Normalization on Performance of AEG Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74208281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='score', ylabel='Count'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalizing Grades and Setting the y labels to the normalized grades\n",
    "\n",
    "# Define the minimum and maximum possible scores for each essay set\n",
    "min_range = [2, 1, 0, 0, 0, 0, 2, 10]\n",
    "max_range = [12, 6, 3, 3, 4, 4, 24, 60]\n",
    "\n",
    "# Function to normalize a score to a range of 0 to 10\n",
    "def normalize(score, min_val, max_val):\n",
    "    normalized = np.interp(score, [min_val, max_val], [0, 10])\n",
    "    return round(normalized)\n",
    "\n",
    "# Apply the normalization function to the 'grade' column for each essay set\n",
    "df['score'] = df.apply(lambda x: normalize(x['grade'], min_range[x['essay_set'] - 1], max_range[x['essay_set'] - 1]), axis=1)\n",
    "\n",
    "\n",
    "# Set y labels to the normalized scores\n",
    "y = df['score']\n",
    "\n",
    "# Check the skewness of the normalized scores and plot a histogram\n",
    "sns.histplot(df['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37da7b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_45 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 14s 39ms/step - loss: 7.7385 - mae: 2.1789\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 5.1559 - mae: 1.7930\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 4.9442 - mae: 1.7544\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 4.7415 - mae: 1.7174\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 4.6360 - mae: 1.6964\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 4.5244 - mae: 1.6796\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 4.4854 - mae: 1.6673\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 4.3606 - mae: 1.6447\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 4.2446 - mae: 1.6206\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 4.1853 - mae: 1.6050\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 4.1096 - mae: 1.5918\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 4.0392 - mae: 1.5794\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 4.0089 - mae: 1.5666\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.9574 - mae: 1.5597\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.9119 - mae: 1.5498\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.8268 - mae: 1.5334\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.8565 - mae: 1.5399\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.8019 - mae: 1.5275\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.7651 - mae: 1.5177\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.7477 - mae: 1.5104\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.6898 - mae: 1.5090\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.6324 - mae: 1.4930\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.6647 - mae: 1.4948\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 3.5368 - mae: 1.4687\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.5661 - mae: 1.4755\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.5295 - mae: 1.4701\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.5065 - mae: 1.4589\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.4602 - mae: 1.4579\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.4006 - mae: 1.4441\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.4406 - mae: 1.4567\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.4191 - mae: 1.4472\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.4067 - mae: 1.4453\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.3528 - mae: 1.4355\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.3649 - mae: 1.4336\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 11s 65ms/step - loss: 3.2784 - mae: 1.4134\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 3.2740 - mae: 1.4131\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 3.2511 - mae: 1.4052\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 3.2521 - mae: 1.4071\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.2157 - mae: 1.3971\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.2220 - mae: 1.4041\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.2415 - mae: 1.4093\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.1707 - mae: 1.3876\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.1340 - mae: 1.3789\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.1266 - mae: 1.3829\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.1160 - mae: 1.3725\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.0844 - mae: 1.3741\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.1131 - mae: 1.3721\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.0994 - mae: 1.3735\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.0871 - mae: 1.3683\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.0819 - mae: 1.3700\n",
      "82/82 [==============================] - 1s 7ms/step\n",
      "Fold 1 MSE: 3.164869029275809\n",
      "Fold 1 RMSE: 1.7790078778003793\n",
      "Fold 1 MAE: 1.3258859784283512\n",
      "Fold 1 Kappa Score: 0.6838175964437941\n",
      "\n",
      "Training Fold 2\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_47 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_48 (LSTM)              (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 13s 40ms/step - loss: 7.8868 - mae: 2.1899\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 5.1283 - mae: 1.7986\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 4.9129 - mae: 1.7484\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 4.6984 - mae: 1.7116\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 4.6356 - mae: 1.6972\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 4.5407 - mae: 1.6785\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 4.3732 - mae: 1.6434\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 4.3120 - mae: 1.6366\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 4.1992 - mae: 1.6110\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 4.1536 - mae: 1.6026\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 4.0777 - mae: 1.5879\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 3.9787 - mae: 1.5665\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.9322 - mae: 1.5600\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.9493 - mae: 1.5675\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.8671 - mae: 1.5450\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.8391 - mae: 1.5376\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.7920 - mae: 1.5198\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 3.7496 - mae: 1.5205\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 3.7195 - mae: 1.5168\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.6723 - mae: 1.5041\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.6448 - mae: 1.4942\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.6485 - mae: 1.4998\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.5878 - mae: 1.4852\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 3.5506 - mae: 1.4728\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 14s 84ms/step - loss: 3.4848 - mae: 1.4635\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 13s 77ms/step - loss: 3.4985 - mae: 1.4650\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 11s 70ms/step - loss: 3.4828 - mae: 1.4685\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 12s 72ms/step - loss: 3.4335 - mae: 1.4532\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.4113 - mae: 1.4519\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.3943 - mae: 1.4380\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 3.3809 - mae: 1.4394\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.3669 - mae: 1.4392\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.2951 - mae: 1.4211\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.2581 - mae: 1.4140\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.2703 - mae: 1.4203\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.2761 - mae: 1.4159\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.2375 - mae: 1.4080\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.2003 - mae: 1.3949\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 3.1981 - mae: 1.3978\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 3.1933 - mae: 1.4031\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.1625 - mae: 1.3941\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.1030 - mae: 1.3729\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.1300 - mae: 1.3845\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.1342 - mae: 1.3789\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 3.1257 - mae: 1.3822\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.1187 - mae: 1.3779\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.0979 - mae: 1.3774\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.0575 - mae: 1.3658\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 3.0330 - mae: 1.3609\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.0312 - mae: 1.3627\n",
      "82/82 [==============================] - 1s 6ms/step\n",
      "Fold 2 MSE: 3.2736030828516376\n",
      "Fold 2 RMSE: 1.809310112405178\n",
      "Fold 2 MAE: 1.3344894026974952\n",
      "Fold 2 Kappa Score: 0.6837504223625992\n",
      "\n",
      "Training Fold 3\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_49 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_50 (LSTM)              (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 10s 33ms/step - loss: 7.6346 - mae: 2.1558\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 5.1104 - mae: 1.7907\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.8533 - mae: 1.7379\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.6934 - mae: 1.7024\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.6287 - mae: 1.6835\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 4.5852 - mae: 1.6825\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 4.4317 - mae: 1.6531\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.3303 - mae: 1.6253\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.2239 - mae: 1.6111\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 4.1430 - mae: 1.5955\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 4.0739 - mae: 1.5908\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.0004 - mae: 1.5661\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 3.9601 - mae: 1.5531\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 3.8533 - mae: 1.5451\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.8706 - mae: 1.5385\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 3.8723 - mae: 1.5377\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.8438 - mae: 1.5366\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.7590 - mae: 1.5184\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.7238 - mae: 1.5140\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.7017 - mae: 1.5066\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.6390 - mae: 1.4899\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.6621 - mae: 1.5006\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.5619 - mae: 1.4787\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 3.5715 - mae: 1.4822\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.5576 - mae: 1.4718\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 3.5308 - mae: 1.4706\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 3.4737 - mae: 1.4533\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4874 - mae: 1.4617\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 3.4365 - mae: 1.4504\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 3.3875 - mae: 1.4369\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 3.4036 - mae: 1.4370\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 3.3610 - mae: 1.4319\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.3506 - mae: 1.4282\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 6s 37ms/step - loss: 3.3248 - mae: 1.4215\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.3134 - mae: 1.4239\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.3070 - mae: 1.4194\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.2563 - mae: 1.4086\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 3.2971 - mae: 1.4169\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.2275 - mae: 1.4067\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.2208 - mae: 1.4022\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.1955 - mae: 1.3966\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.2167 - mae: 1.3994\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 3.1951 - mae: 1.3882\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 3.1601 - mae: 1.3855\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.1001 - mae: 1.3711\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.1258 - mae: 1.3734\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.0962 - mae: 1.3722\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.0758 - mae: 1.3703\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 3.0598 - mae: 1.3618\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 3.0186 - mae: 1.3538\n",
      "82/82 [==============================] - 1s 6ms/step\n",
      "Fold 3 MSE: 3.207707129094412\n",
      "Fold 3 RMSE: 1.791007294539699\n",
      "Fold 3 MAE: 1.3510597302504816\n",
      "Fold 3 Kappa Score: 0.6742782379487073\n",
      "\n",
      "Training Fold 4\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_51 (LSTM)              (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 13s 36ms/step - loss: 7.5721 - mae: 2.1523\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 5.1688 - mae: 1.7986\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 4.8554 - mae: 1.7410\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 4.7091 - mae: 1.7093\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 4.6064 - mae: 1.6915\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 4.5138 - mae: 1.6739\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 4.4115 - mae: 1.6527\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 4.3892 - mae: 1.6479\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 8s 52ms/step - loss: 4.2295 - mae: 1.6156\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 4.1235 - mae: 1.6017\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 4.1223 - mae: 1.5972\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 4.0846 - mae: 1.5847\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 4.0128 - mae: 1.5788\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.9428 - mae: 1.5561\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 3.9191 - mae: 1.5557\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.8516 - mae: 1.5400\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.8094 - mae: 1.5309\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.8174 - mae: 1.5291\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.7193 - mae: 1.5078\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.7295 - mae: 1.5061\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.6352 - mae: 1.4951\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.6234 - mae: 1.4888\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.5856 - mae: 1.4831\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.5823 - mae: 1.4815\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.5320 - mae: 1.4661\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.4893 - mae: 1.4658\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.5327 - mae: 1.4748\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 7s 42ms/step - loss: 3.4287 - mae: 1.4444\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 7s 46ms/step - loss: 3.4213 - mae: 1.4459\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 11s 68ms/step - loss: 3.4107 - mae: 1.4423\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 3.3999 - mae: 1.4438\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 3.3235 - mae: 1.4235\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 3.3311 - mae: 1.4231\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 3.3550 - mae: 1.4290\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 3.3172 - mae: 1.4212\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 3.2955 - mae: 1.4147\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 3.2535 - mae: 1.4045\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 8s 46ms/step - loss: 3.2104 - mae: 1.3999\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 3.2596 - mae: 1.3992\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 3.1713 - mae: 1.3877\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.1582 - mae: 1.3782\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.1549 - mae: 1.3823\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.1377 - mae: 1.3895\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.1417 - mae: 1.3785\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.1099 - mae: 1.3769\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 3.1231 - mae: 1.3849\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 7s 45ms/step - loss: 3.0868 - mae: 1.3697\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 3.0778 - mae: 1.3700\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 3.0667 - mae: 1.3669\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 3.0347 - mae: 1.3603\n",
      "82/82 [==============================] - 1s 7ms/step\n",
      "Fold 4 MSE: 3.2073217726396916\n",
      "Fold 4 RMSE: 1.7908997103801463\n",
      "Fold 4 MAE: 1.3421965317919076\n",
      "Fold 4 Kappa Score: 0.6731169442946735\n",
      "\n",
      "Training Fold 5\n",
      "\n",
      "Training Word2Vec Model...\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_53 (LSTM)              (None, 1, 300)            721200    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " lstm_54 (LSTM)              (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814705 (3.11 MB)\n",
      "Trainable params: 814705 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "163/163 [==============================] - 12s 45ms/step - loss: 7.4974 - mae: 2.1407\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 16s 100ms/step - loss: 5.1582 - mae: 1.7895\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 4.8977 - mae: 1.7442\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 4.7510 - mae: 1.7139\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 4.6537 - mae: 1.6943\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 4.4569 - mae: 1.6600\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 4.4278 - mae: 1.6560\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 4.3179 - mae: 1.6268\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 4.2456 - mae: 1.6135\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 9s 56ms/step - loss: 4.1892 - mae: 1.6093\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 9s 55ms/step - loss: 4.0941 - mae: 1.5838\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 4.0486 - mae: 1.5771\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.9143 - mae: 1.5486\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.9100 - mae: 1.5508\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.9283 - mae: 1.5560\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 3.8344 - mae: 1.5255\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.8208 - mae: 1.5342\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.8332 - mae: 1.5299\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.7028 - mae: 1.5006\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.7570 - mae: 1.5167\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 9s 57ms/step - loss: 3.7076 - mae: 1.5094\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 10s 58ms/step - loss: 3.6277 - mae: 1.4935\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 3.5949 - mae: 1.4795\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 3.6070 - mae: 1.4840\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 3.5283 - mae: 1.4702\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4998 - mae: 1.4658\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4650 - mae: 1.4541\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4755 - mae: 1.4552\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4340 - mae: 1.4406\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4353 - mae: 1.4478\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.4228 - mae: 1.4470\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 3.3642 - mae: 1.4323\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 9s 52ms/step - loss: 3.3905 - mae: 1.4340\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.3420 - mae: 1.4222\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.2854 - mae: 1.4152\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.2505 - mae: 1.4092\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.2473 - mae: 1.4062\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.2132 - mae: 1.4025\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.2650 - mae: 1.4138\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.1853 - mae: 1.3903\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.1668 - mae: 1.3865\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.1500 - mae: 1.3826\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 9s 54ms/step - loss: 3.1425 - mae: 1.3829\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.0960 - mae: 1.3690\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 9s 53ms/step - loss: 3.1287 - mae: 1.3753\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 8s 50ms/step - loss: 3.0391 - mae: 1.3612\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 8s 51ms/step - loss: 3.1005 - mae: 1.3717\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 3.0910 - mae: 1.3697\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 3.0198 - mae: 1.3521\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 8s 49ms/step - loss: 3.0335 - mae: 1.3553\n",
      "82/82 [==============================] - 2s 11ms/step\n",
      "Fold 5 MSE: 3.3934489402697494\n",
      "Fold 5 RMSE: 1.8421316294634729\n",
      "Fold 5 MAE: 1.3749518304431598\n",
      "Fold 5 Kappa Score: 0.6651624187708334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yabio\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 2-Layer LSTM Model Training and Testing using Normalized Grades\n",
    "\n",
    "# Initialize K-Fold cross-validation with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "mse_scores = []  # Mean Squared Error (MSE)\n",
    "rmse_scores = []  # Root Mean Squared Error (RMSE)\n",
    "mae_scores = []  # Mean Absolute Error (MAE)\n",
    "kappa_scores = []  # Cohen's Kappa scores\n",
    "\n",
    "count = 1  # Initialize fold counter\n",
    "for trainkf, testkf in kf.split(df):\n",
    "    print(\"\\nTraining Fold {}\\n\".format(count))\n",
    "    X_train, X_test, y_train, y_test = df.iloc[trainkf], df.iloc[testkf], y.iloc[trainkf], y.iloc[testkf]\n",
    "        \n",
    "    train_essays = [essay.split() for essay in X_train['token_essay']]\n",
    "    test_essays = [essay.split() for essay in X_test['token_essay']]\n",
    "                 \n",
    "    # Initializing variables for Word2Vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model_lstm = Word2Vec(train_essays, \n",
    "                     workers=num_workers, \n",
    "                     vector_size=num_features, \n",
    "                     min_count=min_word_count, \n",
    "                     window=context, \n",
    "                     sample=downsampling)\n",
    "\n",
    "    model_lstm.wv.save_word2vec_format('Models/word2vecmodel_lstm_score.bin', binary=True)\n",
    "\n",
    "    training_vectors = generate_average_feature_vectors(train_essays, model_lstm, num_features)\n",
    "    testing_vectors = generate_average_feature_vectors(test_essays, model_lstm, num_features)\n",
    "\n",
    "    training_vectors = np.array(training_vectors)\n",
    "    testing_vectors = np.array(testing_vectors)\n",
    "    \n",
    "    # Reshape train and test vectors to 3 dimensions (1 represents one timestep)\n",
    "    training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "    testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "    \n",
    "    # Create and train the LSTM model\n",
    "    lstm_model_score = get_model()\n",
    "    lstm_model_score.fit(training_vectors, y_train, batch_size=64, epochs=50)\n",
    "    \n",
    "    # Make predictions with the model\n",
    "    y_pred = lstm_model_score.predict(testing_vectors)\n",
    "    \n",
    "    if count == 5:\n",
    "        # Save the trained model after the final fold\n",
    "        lstm_model_score.save('Models/model_lstm_score.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer\n",
    "    y_pred = np.around(y_pred)    \n",
    "    \n",
    "    # Calculate evaluation metrics for this fold\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
    "    \n",
    "    print(\"Fold {} MSE: {}\".format(count, mse))\n",
    "    print(\"Fold {} RMSE: {}\".format(count, rmse))\n",
    "    print(\"Fold {} MAE: {}\".format(count, mae))\n",
    "    print(\"Fold {} Kappa Score: {}\".format(count, kappa))\n",
    "    \n",
    "    # Store evaluation metrics for this fold\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    kappa_scores.append(kappa)\n",
    "\n",
    "    count += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f4d922",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE for LSTM 2-layers with normalized Grades:  3.24938999082626\n",
      "Average RMSE for LSTM 2-layers with normalized Grades:  1.802471324917775\n",
      "Average MAE for LSTM 2-layers with normalized Grades:  1.3457166947222792\n",
      "Average Kappa for LSTM 2-layers with normalized Grades:  0.6760251239641214\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP8ElEQVR4nO3de3zP9f//8fvsbCeGzcbMnGaIpGTESM5JpU+SkFN8csgpOZVDafVBLSW+ZTOSQz6TEgk5Z87zIacP5ZS2HIqJ7MDz94ff3h9v27zQeI/drpfL63Lxer6er9fr8Xp7vd7b/f1+vZ5zMsYYAQAAAAByVcjRBQAAAABAfkdwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAvK5w4cPy8nJyTYVKlRIRYsWVePGjbVs2TJHlydJatiwoRo2bGibv3DhgkaPHq3Vq1c7rKbryXpN4+PjHbbvCRMmXLff+fPn9e6776pGjRry9fWVj4+Pypcvr2effVZr1qyRJJUtW9bu3MhtyjrOrPkXX3wxx32OHTvW1ufw4cPXrW/lypXq2rWrKleuLC8vL5UqVUpt2rTRtm3bbvi1ePHFF1W2bNkb7l9QODk5afTo0bb5PXv2aPTo0Tn+nzRs2FDVqlW75X1lnUO9evXKtmz16tVycnLSv//971veviPldJ3Hx8ff0Pmd127mXL98+bJmzZqlZs2aKSAgQK6uripSpIjq1KmjCRMm6NSpU7e32KuULVs21/cLoCBycXQBAG5M37599fzzz+vSpUvat2+fxowZo5YtW2rlypVq0KCBo8uzc+HCBY0ZM0aS7AJVfhEUFKTExESVL1/e0aXk6NKlS2ratKl27dqlV199VbVr15YkHThwQIsWLdK6desUFRWlL7/8Umlpabb1pk2bptjYWC1dulR+fn629quP08fHR/Pnz9eHH34oHx8fW7sxRvHx8fL19VVqaqpljVOmTNHp06f1yiuvqEqVKjp58qQmTpyoOnXq6LvvvtOjjz6aFy9FgZSYmKjSpUvb5vfs2aMxY8aoYcOGty1oxsbGasCAAQoPD78t288vWrVqpcTERAUFBTm6lBz99ddfatOmjVasWKF27dpp0qRJCg4OVmpqqjZs2KDx48frq6++0rp16xxdKlAgEZyAu0SZMmVUp04dSVK9evVUsWJFRUVFKTY2Nt8Fp/zO3d3d9lrmR2vXrtWGDRsUFxenLl262NqbNWumPn366PLly5KkmjVr2q23dOlSSVKtWrVUvHjxHLfdpk0bJSQkaO7cuerRo4etfeXKlTp06JB69OihTz/91LLGyZMnKyAgwK6tefPmqlChgt5+++17IjhduHBBhQsXvuP7vdPnZmRkpPbs2aPhw4crISHhtu3nr7/+koeHh5ycnG7bPqyUKFFCJUqUcNj+rfTv31/Lly/X7Nmz1b59e7tljz/+uEaOHKnPP//8utswxujixYvy9PS8naUCBRK36gF3qQcffFCS9Ntvv9m1p6SkqGfPnipdurTc3NwUFhamMWPGKDMz067flClTVKNGDXl7e8vHx0eVK1fW8OHDbctHjx6d4y84Vre6HD582PaLyZgxY7LdHnby5Em99NJLCgkJkbu7u0qUKKF69eppxYoV1z3e3G51yanO+fPn6+GHH5afn58KFy6scuXKqWvXrnY1XnsLT9Z2du/erfbt28vPz0+BgYHq2rWrzp49a7f9M2fOqFu3bvL395e3t7datWqln3/+OdstVrfq9OnTkpTrp+KFCt36W7efn5+eeuopxcXF2bXHxcWpXr16qlSp0g1t59rQJEne3t6qUqWKjh07dsv1TZ48WQ0aNFBAQIC8vLx033336V//+pcyMjJsfd588025uLjkuJ+uXbuqWLFiunjxoq1t3rx5ioyMlJeXl7y9vdWsWTMlJSXZrffiiy/K29tbu3btUtOmTeXj46PGjRtLkpKSkvT4448rICBA7u7uCg4OVqtWrfTLL79c9zgKFSqkEydO2NomTpwoJycn9e7d29Z2+fJlFS1aVIMGDbK1XX0excfH6x//+IckqVGjRtluv8yyZcsW1a9f33a+v/POO7aAbcXf319Dhw7VggULtHHjRsv+69evV+PGjeXj46PChQurbt26Wrx4sV2frPeJZcuWqWvXripRooQKFy6stLQ02+2FiYmJqlu3rjw9PVW2bFlNnz5dkrR48WI98MADKly4sO677z7bBwJZDh48qC5duqhixYoqXLiwSpUqpdatW2vXrl2WtV/7/pV1O2JO07XvNzdyHmXtIzw8XO7u7oqIiNDMmTMt65Kk5ORkxcXFqVWrVtlCU5bChQvbfeAhXTlf+vTpo6lTpyoiIkLu7u6aMWOGpCvvwQ8//LD8/f3l6+urBx54QLGxsTLG2G0jIyNDQ4YMUcmSJVW4cGE98sgj2rx5c4415NXPGOBuxDdOwF3q0KFDkmT3i25KSopq166tQoUK6Y033lD58uWVmJiot956S4cPH7b9YjJ37ly9/PLL6tu3ryZMmKBChQrp4MGD2rNnz9+uKygoSEuXLlXz5s3VrVs3de/eXZJsYapjx47avn27xo0bp0qVKunMmTPavn27LSz8XYmJiWrXrp3atWun0aNHy8PDQ0eOHNHKlStvaP22bduqXbt26tatm3bt2qVhw4ZJki1oXL58Wa1bt9bWrVs1evRoPfDAA0pMTFTz5s3zpH7pSih2dXXVK6+8ojfeeEOPPvpont5a1K1bNzVu3Fh79+5VRESEzpw5owULFujjjz/+W/8PZ8+e1fbt2//Wt00//fSTnn/+eYWFhcnNzU3/+c9/NG7cOO3bt8/2f9CzZ0+NGzdO//d//6e33nrLtu7vv/+uuXPnqk+fPvLw8JAkvf322xo5cqS6dOmikSNHKj09XePHj1f9+vW1efNmValSxbZ+enq6nnjiCfXs2VNDhw5VZmamzp8/ryZNmigsLEyTJ09WYGCgUlJStGrVKp07dy7X43jsscdkjNH3339v+yV4xYoV8vT01PLly239tm7dqjNnzuixxx7LcTutWrXS22+/reHDh2vy5Ml64IEHJNnffpmSkqIOHTpo0KBBGjVqlL788ksNGzZMwcHB6tSp0w297q+88oo++ugjDRkyRGvXrs2135o1a9SkSRNVr15dsbGxcnd318cff6zWrVtrzpw5ateunV3/rl27qlWrVvrss890/vx5ubq62mru0qWLhgwZotKlS+vDDz9U165ddezYMf373//W8OHD5efnp7Fjx+rJJ5/Uzz//rODgYEnSr7/+qmLFiumdd95RiRIl9Pvvv2vGjBl6+OGHlZSUdFO3G2Zdv1c7cOCAunXrpqpVq9rabvQ8io+PV5cuXdSmTRtNnDhRZ8+e1ejRo5WWlmb5gceqVauUmZmpJ5544obrz7Jw4UKtW7dOb7zxhkqWLGn7YOPw4cPq2bOnypQpI0nauHGj+vbtq+PHj+uNN96wrd+jRw/NnDlTgwcPVpMmTfTjjz/q6aefznaO54efMYBDGQD52qFDh4wk8+6775qMjAxz8eJFs2PHDhMZGWmCgoLMoUOHbH179uxpvL29zZEjR+y2MWHCBCPJ7N692xhjTJ8+fUyRIkWuu99Ro0aZnN4ipk+fbiTZ7TcqKspERUXZ5k+ePGkkmVGjRmVb39vb2/Tv39/6wK/RuXNnExoaalln1rGeOXMm121lvabTp0/Ptp1//etfdn1ffvll4+HhYS5fvmyMMWbx4sVGkpkyZYpdv+jo6FyPOad9jx8//rr9YmNjjbe3t5FkJJmgoCDTqVMns3bt2lzXyTqGkydP5rhckundu7e5fPmyCQsLM4MHDzbGGDN58mTj7e1tzp07Z8aPH5/t//dGdejQwbi4uJitW7feUP/c/k+zXLp0yWRkZJiZM2caZ2dn8/vvv9utGxAQYNLS0mxt7777rilUqJCt9qNHjxoXFxfTt29fu+2eO3fOlCxZ0jz77LN225Nk4uLi7Ppu3brVSDILFy68oWO6WunSpU3Xrl2NMcakpaUZLy8v89prrxlJtmt03LhxxtXV1fz555+29a49j+bPn28kmVWrVmXbR1RUlJFkNm3aZNdepUoV06xZM8saQ0NDTatWrYwxxnz66adGklm0aJExxphVq1YZSWb+/Pm2/nXq1DEBAQHm3LlztrbMzExTrVo1U7p0adt1kvU+0alTp1xrvvo8OX36tHF2djaenp7m+PHjtvYdO3YYSWbSpEm5HkNmZqZJT083FStWNAMGDLC153Sd5/T+dbXffvvNlCtXzlStWtX88ccfxpgbP48uXbpkgoODzQMPPGB7HYwx5vDhw8bV1fW657oxxrzzzjtGklm6dGm2ZRkZGXbT1SQZPz8/u+sjJ1nX09ixY02xYsVsNe7du9dIsnvtjDHm888/N5JM586dbW15+TMGuBtxqx5wl3jttdfk6uoqDw8P3X///frxxx+1aNEiu9tJvvnmGzVq1EjBwcHKzMy0TS1atJAk22hstWvX1pkzZ9S+fXt99dVXd3SUptq1ays+Pl5vvfWWNm7caHcLVl546KGHJEnPPvusvvjiCx0/fvym1r/2097q1avr4sWLtluusl7DZ5991q5fbrfW3KquXbvql19+0ezZs9WvXz+FhIRo1qxZioqK0vjx4//WtrNunfzss8+UmZmp2NhYPfvss/L29r7lbb7++uv6/PPP9f7776tWrVq29suXL9udi5cuXbrudpKSkvTEE0+oWLFicnZ2lqurqzp16qRLly7pv//9r63fK6+8ohMnTmj+/Pm2/UyZMkWtWrWyXRPfffedMjMz1alTJ7saPDw8FBUVleOoj23btrWbr1ChgooWLarXXntNU6dOvalPzBs3bmy7BXXDhg26cOGCBg4cqOLFi9u+dVqxYoXt9q9bVbJkSdsAIlmqV6+uI0eO3NR2unTpoipVqmjo0KE53uZ3/vx5bdq0Sc8884zdueLs7KyOHTvql19+0f79++3Wufb1zBIUFGR3nvj7+ysgIED333+/7ZslSYqIiJAku2PJzMzU22+/rSpVqsjNzU0uLi5yc3PTgQMHtHfv3ps65muPr1WrVrp48aK+/fZbFSlSRNKNn0f79+/Xr7/+queff97u9uHQ0FDVrVv3luvasWOHXF1d7aZr37MfffRRFS1aNNu6K1eu1GOPPSY/Pz/b9fTGG2/o9OnTtve0VatWSZI6dOhgt+6zzz4rFxf7G5Puhp8xwO1EcALuEq+88oq2bNmi9evXa8KECcrIyFCbNm3sbq367bfftGjRomw/ZLNuOcn64dWxY0fFxcXpyJEjatu2rQICAvTwww/b3UJ0u8ybN0+dO3fWtGnTFBkZKX9/f3Xq1EkpKSl5sv0GDRpo4cKFtl90SpcurWrVqmnOnDk3tH6xYsXs5t3d3SVdebBduvL8kYuLi/z9/e36BQYG5kH19vz8/NS+fXt98MEH2rRpk3bu3KnAwECNGDFCZ86c+Vvb7tKli06ePKm3335b27dvV7du3W55W2PGjNFbb72lcePGqU+fPnbLxo4da3cuXm8kw6NHj6p+/fo6fvy4PvjgA61bt05btmzR5MmTJf3v/0C6MjBG/fr1bcu++eYbHT582G7/Wc//PfTQQ9muiXnz5mX7Za5w4cLy9fW1a/Pz89OaNWt0//33a/jw4apataqCg4M1atQoy9D/2GOP6ejRozpw4IBWrFihmjVrKiAgQI8++qhWrFihv/76Sxs2bMj1Nr0bde05K105b69+vW6Es7Oz3n77be3evdv2jMzV/vjjDxljcrxtNCvsXHurZ263mF57/UiSm5tbtnY3NzdJsntmbeDAgXr99df15JNPatGiRdq0aZO2bNmiGjVq3PQxZ8nMzNQzzzyj//73v1qyZIlCQkJsy270PMo69pIlS2bbfk5t18q6ne7awBseHq4tW7Zoy5Yt2Z5vypLT67x582Y1bdpUkvTpp5/qhx9+0JYtWzRixAhJ9u9pOdXo4uKS7dy6G37GALcTzzgBd4nSpUvbBoSoV6+eSpYsqRdeeEGjRo3SRx99JEkqXry4qlevrnHjxuW4jas/ye3SpYu6dOmi8+fPa+3atRo1apQef/xx/fe//1VoaKjtGZG0tDRbeJD0tz85LF68uGJiYhQTE6OjR4/q66+/1tChQ3XixIlsD4FfzcPDw27o7evV06ZNG7Vp00ZpaWnauHGjoqOj9fzzz6ts2bKKjIz8W/UXK1ZMmZmZ+v333+1+ycur4Hc9VatW1XPPPaeYmBj997//zfYtw80ICQnRY489pjFjxig8PPyWPxEfM2aMRo8erdGjR+f44PdLL72kxx9/3DZ/9bl0rYULF+r8+fNasGCBQkNDbe07duzIsX+/fv30j3/8Q9u3b9dHH32kSpUqqUmTJrblWSML/vvf/7bbXm5yG+3tvvvu09y5c2WM0c6dOxUfH6+xY8fK09NTQ4cOzXV7WYNLrFixQsuXL7fV1rhxY40cOVJr165VWlra3w5OealNmzaqV6+eRo0apU8++cRuWdGiRVWoUCElJydnW+/XX3+VpGyjOd6OEfRmzZqlTp066e2337ZrP3XqlO1bopv10ksv6fvvv9eSJUtUo0YNu2U3eh5lhYyc3gtu5P2hYcOGcnFx0ddff62XXnrJ1u7p6Wl77//mm29yXDen13nu3LlydXXVN998Y3s/l65cZ7nVXapUKVt7ZmZmtiCclz9jgLsRwQm4S3Xo0EHTpk3Tp59+qldffVWhoaF6/PHHtWTJEpUvXz7H2zZy4uXlpRYtWig9PV1PPvmkdu/erdDQUNvtTjt37rTd/iZJixYtstzmtd/S5KZMmTLq06ePvv/+e/3www/X7Vu2bFmdOHFCv/32m+3bnfT0dH333XfXrSMqKkpFihTRd999p6SkpL8dnKKiovSvf/1L8+bN0z//+U9b+9y5c//Wdq92+vRp+fj42D5tv9q+ffsk2f+CcqsGDRokT09P26htN+vNN9/U6NGjNXLkSI0aNSrHPsHBwTdca9Yvf1eHK2NMrsOjP/XUUypTpowGDRqkNWvW6P3337f7BbJZs2ZycXHRTz/9lOstYzfDyclJNWrU0Pvvv6/4+Hht3779uv2DgoJUpUoVJSQkaNu2bbZf9Js0aaKePXvqvffek6+vr931lZMbvZ7yyrvvvqtHHnlEkyZNsmv38vLSww8/rAULFmjChAm24a6z/mBr6dKlb3hUxr/DyckpWwBfvHixjh8/rgoVKtz09kaOHKnp06drxowZOYbYGz2PwsPDFRQUpDlz5mjgwIG2c/HIkSPasGGD5XUQFBSkrl276pNPPtHcuXP13HPP3fSxXM3JyUkuLi5ydna2tf3111/67LPP7Ppl/a29zz//3O72yS+++CLbSHl5+TMGuBsRnIC72LvvvquHH35Yb775pqZNm6axY8dq+fLlqlu3rvr166fw8HBdvHhRhw8f1pIlSzR16lSVLl1aPXr0kKenp+rVq6egoCClpKQoOjpafn5+tl/iWrZsKX9/f3Xr1k1jx46Vi4uL4uPjb2ioaR8fH4WGhuqrr75S48aN5e/vr+LFi6to0aJq1KiRnn/+eVWuXFk+Pj7asmWLli5dqqeffvq622zXrp3eeOMNPffcc3r11Vd18eJFTZo0KdszM2+88YZ++eUXNW7cWKVLl9aZM2f0wQcfyNXVVVFRUbf+Yv9/zZs3V7169TRo0CClpqaqVq1aSkxMtA05fKNDhe/atUv//ve/s7U/9NBD2rJli1555RV16NBBdevWVbFixXTixAnNmTNHS5cutd2C+Hc1bdrUdivPzZo4caLeeOMNNW/eXK1atco2jPWt/C2iJk2ayM3NTe3bt9eQIUN08eJFTZkyRX/88UeO/Z2dndW7d2+99tpr8vLysg15n6Vs2bIaO3asRowYoZ9//lnNmzdX0aJF9dtvv2nz5s3y8vKy/aHm3HzzzTf6+OOP9eSTT6pcuXIyxmjBggU6c+aM3bdbuWncuLE+/PBD2/UmSWFhYQoLC9OyZcv0xBNPZHuO5FrVqlWTJH3yySfy8fGRh4eHwsLCcrxFLy/Uq1dPbdq00VdffZVtWXR0tJo0aaJGjRpp8ODBcnNz08cff6wff/xRc+bMuSN/o+nxxx9XfHy8KleurOrVq2vbtm0aP378LV0T8+fP17hx4/TMM8+oUqVKduexu7u7atasecPnUaFChfTmm2+qe/fueuqpp9SjRw+dOXNGo0ePvqFb9SQpJiZGhw4dUocOHfT111+rTZs2Cg4O1oULF7Rv3z7NnTtXHh4ettEJr6dVq1Z677339Pzzz+ull17S6dOnNWHChGyhMyIiQi+88IJiYmLk6uqqxx57TD/++KMmTJiQ7dbVvPwZA9yVHDs2BQArVqOw/eMf/zAuLi7m4MGDxpgrI9r169fPhIWFGVdXV+Pv729q1aplRowYYRu5a8aMGaZRo0YmMDDQuLm5meDgYPPss8+anTt32m178+bNpm7dusbLy8uUKlXKjBo1ykybNs1yVD1jjFmxYoWpWbOmcXd3t43MdPHiRdOrVy9TvXp14+vrazw9PU14eLgZNWqUOX/+vOVrsWTJEnP//fcbT09PU65cOfPRRx9lG1Xvm2++MS1atDClSpUybm5uJiAgwLRs2dKsW7cu22ua06h6145Il9MoXL///rvp0qWLKVKkiClcuLBp0qSJ2bhxo5FkPvjgg+seQ9a+c5umT59ujh07ZkaOHGnq1atnSpYsaVxcXIyPj495+OGHzYcffmgyMzNz3PaNjqp3PTc6ql7WyGi5TTcip1H1Fi1aZGrUqGE8PDxMqVKlzKuvvmq+/fbbXEeVO3z4sJFkevXqlet+Fi5caBo1amR8fX2Nu7u7CQ0NNc8884xZsWKFXS1eXl7Z1t23b59p3769KV++vPH09DR+fn6mdu3aJj4+/oaO8auvvjKSTJMmTezae/ToketoccphdMaYmBgTFhZmnJ2d7c7dqKgoU7Vq1WzbsBqxMMvVo+pdbc+ePbZ9XT2qnjHGrFu3zjz66KPGy8vLeHp6mjp16thG4suSdd1s2bIl27Zzqzm3Wq49b//44w/TrVs3ExAQYAoXLmweeeQRs27dumzvQzcyql7WNZPTdO3rdyPnkTHGTJs2zVSsWNG4ubmZSpUqmbi4uBv+/zDmyuh3M2fONE2aNDHFixc3Li4utvPu9ddfN7/88st1X5+rxcXFmfDwcOPu7m7KlStnoqOjTWxsbLZrPC0tzQwaNMgEBAQYDw8PU6dOHZOYmGhCQ0PtRtUzJm9/xgB3GydjrvkraACAmzZ79mx16NBBP/zww98aQQs358MPP1S/fv30448/2v3dHQAA8hrBCQBu0pw5c3T8+HHdd999KlSokDZu3Kjx48erZs2atuF4cXslJSXp0KFD6tmzp+rVq5ftgXcAAPIawQkAbtI333yj0aNH6+DBgzp//ryCgoL05JNP6q233sr2TABuj7JlyyolJUX169fXZ599dsPPkAAAcKsITgAAAABggT+ACwAAAAAWCE4AAAAAYIHgBAAAAAAWCtwfwL18+bJ+/fVX+fj43JE/1AcAAAAgfzLG6Ny5cwoODrb8I/YFLjj9+uuvCgkJcXQZAAAAAPKJY8eOqXTp0tftU+CCk4+Pj6QrLw7DBgMAAAAFV2pqqkJCQmwZ4XoKXHDKuj3P19eX4AQAAADghh7hYXAIAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALDg4ugC7gW1Xp3p6BJQQGwb38nRJQAAABRIfOMEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYcGpymTJmi6tWry9fXV76+voqMjNS333573XXWrFmjWrVqycPDQ+XKldPUqVPvULUAAAAACiqHBqfSpUvrnXfe0datW7V161Y9+uijatOmjXbv3p1j/0OHDqlly5aqX7++kpKSNHz4cPXr108JCQl3uHIAAAAABYmLI3feunVru/lx48ZpypQp2rhxo6pWrZqt/9SpU1WmTBnFxMRIkiIiIrR161ZNmDBBbdu2zXEfaWlpSktLs82npqbm3QEAAAAAKBDyzTNOly5d0ty5c3X+/HlFRkbm2CcxMVFNmza1a2vWrJm2bt2qjIyMHNeJjo6Wn5+fbQoJCcnz2gEAAADc2xwenHbt2iVvb2+5u7urV69e+vLLL1WlSpUc+6akpCgwMNCuLTAwUJmZmTp16lSO6wwbNkxnz561TceOHcvzYwAAAABwb3PorXqSFB4erh07dujMmTNKSEhQ586dtWbNmlzDk5OTk928MSbH9izu7u5yd3fP26IBAAAAFCgOD05ubm6qUKGCJOnBBx/Uli1b9MEHH+j//u//svUtWbKkUlJS7NpOnDghFxcXFStW7I7UCwAAAKDgcfitetcyxtgN5nC1yMhILV++3K5t2bJlevDBB+Xq6nonygMAAABQADk0OA0fPlzr1q3T4cOHtWvXLo0YMUKrV69Whw4dJF15PqlTp062/r169dKRI0c0cOBA7d27V3FxcYqNjdXgwYMddQgAAAAACgCH3qr322+/qWPHjkpOTpafn5+qV6+upUuXqkmTJpKk5ORkHT161NY/LCxMS5Ys0YABAzR58mQFBwdr0qRJuQ5FDgAAAAB5wclkja5QQKSmpsrPz09nz56Vr69vnmyz1qsz82Q7gJVt4ztZdwIAAMANuZlskO+ecQIAAACA/IbgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWCE4AAAAAYIHgBAAAAAAWHBqcoqOj9dBDD8nHx0cBAQF68skntX///uuus3r1ajk5OWWb9u3bd4eqBgAAAFDQODQ4rVmzRr1799bGjRu1fPlyZWZmqmnTpjp//rzluvv371dycrJtqlix4h2oGAAAAEBB5OLInS9dutRufvr06QoICNC2bdvUoEGD664bEBCgIkWK3MbqAAAAAOCKfPWM09mzZyVJ/v7+ln1r1qypoKAgNW7cWKtWrcq1X1pamlJTU+0mAAAAALgZ+SY4GWM0cOBAPfLII6pWrVqu/YKCgvTJJ58oISFBCxYsUHh4uBo3bqy1a9fm2D86Olp+fn62KSQk5HYdAgAAAIB7lJMxxji6CEnq3bu3Fi9erPXr16t06dI3tW7r1q3l5OSkr7/+OtuytLQ0paWl2eZTU1MVEhKis2fPytfX92/XLUm1Xp2ZJ9sBrGwb38nRJQAAANwzUlNT5efnd0PZIF9849S3b199/fXXWrVq1U2HJkmqU6eODhw4kOMyd3d3+fr62k0AAAAAcDMcOjiEMUZ9+/bVl19+qdWrVyssLOyWtpOUlKSgoKA8rg4AAAAArnBocOrdu7dmz56tr776Sj4+PkpJSZEk+fn5ydPTU5I0bNgwHT9+XDNnXrkdLiYmRmXLllXVqlWVnp6uWbNmKSEhQQkJCQ47DgAAAAD3NocGpylTpkiSGjZsaNc+ffp0vfjii5Kk5ORkHT161LYsPT1dgwcP1vHjx+Xp6amqVatq8eLFatmy5Z0qGwAAAEABk28Gh7hTbuYBsBvF4BC4UxgcAgAAIO/cdYNDAAAAAEB+RnACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACwQHACAAAAAAsEJwAAAACw4NDgFB0drYceekg+Pj4KCAjQk08+qf3791uut2bNGtWqVUseHh4qV66cpk6degeqBQAAAFBQOTQ4rVmzRr1799bGjRu1fPlyZWZmqmnTpjp//nyu6xw6dEgtW7ZU/fr1lZSUpOHDh6tfv35KSEi4g5UDAAAAKEhcHLnzpUuX2s1Pnz5dAQEB2rZtmxo0aJDjOlOnTlWZMmUUExMjSYqIiNDWrVs1YcIEtW3b9naXDAAAAKAAylfPOJ09e1aS5O/vn2ufxMRENW3a1K6tWbNm2rp1qzIyMrL1T0tLU2pqqt0EAAAAADcj3wQnY4wGDhyoRx55RNWqVcu1X0pKigIDA+3aAgMDlZmZqVOnTmXrHx0dLT8/P9sUEhKS57UDAAAAuLflm+DUp08f7dy5U3PmzLHs6+TkZDdvjMmxXZKGDRums2fP2qZjx47lTcEAAAAACgyHPuOUpW/fvvr666+1du1alS5d+rp9S5YsqZSUFLu2EydOyMXFRcWKFcvW393dXe7u7nlaLwAAAICCxaHfOBlj1KdPHy1YsEArV65UWFiY5TqRkZFavny5XduyZcv04IMPytXV9XaVCgAAAKAAc2hw6t27t2bNmqXZs2fLx8dHKSkpSklJ0V9//WXrM2zYMHXq1Mk236tXLx05ckQDBw7U3r17FRcXp9jYWA0ePNgRhwAAAACgAHBocJoyZYrOnj2rhg0bKigoyDbNmzfP1ic5OVlHjx61zYeFhWnJkiVavXq17r//fr355puaNGkSQ5EDAAAAuG0c+oxT1qAO1xMfH5+tLSoqStu3b78NFQEAAABAdvlmVD0AAAAAyK8ITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABg4W8Fp/T0dO3fv1+ZmZl5VQ8AAAAA5Du3FJwuXLigbt26qXDhwqpataqOHj0qSerXr5/eeeedPC0QAAAAABztloLTsGHD9J///EerV6+Wh4eHrf2xxx7TvHnz8qw4AAAAAMgPXG5lpYULF2revHmqU6eOnJycbO1VqlTRTz/9lGfFAQAAAEB+cEvB6eTJkwoICMjWfv78ebsgBQBAQVHvw3qOLgEFxA99f3B0CUCBdEu36j300ENavHixbT4rLH366aeKjIzMm8oAAAAAIJ+4pW+coqOj1bx5c+3Zs0eZmZn64IMPtHv3biUmJmrNmjV5XSMAAAAAONQtfeNUt25dbdiwQRcuXFD58uW1bNkyBQYGKjExUbVq1crrGgEAAADAoW76G6eMjAy99NJLev311zVjxozbURMAAAAA5Cs3/Y2Tq6urvvzyy9tRCwAAAADkS7d0q95TTz2lhQsX5nEpAAAAAJA/3dLgEBUqVNCbb76pDRs2qFatWvLy8rJb3q9fvzwpDgAAAADyg1sKTtOmTVORIkW0bds2bdu2zW6Zk5MTwQkAAADAPeWWgtOhQ4fyug4AAAAAyLdu6RmnqxljZIzJi1oAAAAAIF+65eA0c+ZM3XffffL09JSnp6eqV6+uzz77LC9rAwAAAIB84ZZu1Xvvvff0+uuvq0+fPqpXr56MMfrhhx/Uq1cvnTp1SgMGDMjrOgEAAADAYW4pOH344YeaMmWKOnXqZGtr06aNqlatqtGjRxOcAAAAANxTbulWveTkZNWtWzdbe926dZWcnPy3iwIAAACA/OSWglOFChX0xRdfZGufN2+eKlas+LeLAgAAAID85JZu1RszZozatWuntWvXql69enJyctL69ev1/fff5xioAAAAAOBudkvfOLVt21abNm1S8eLFtXDhQi1YsEDFixfX5s2b9dRTT+V1jQAAAADgULf0jZMk1apVS7NmzcrLWgAAAAAgX7qlb5yWLFmi7777Llv7d999p2+//fZvFwUAAAAA+cktBaehQ4fq0qVL2dqNMRo6dOjfLgoAAAAA8pNbCk4HDhxQlSpVsrVXrlxZBw8e/NtFAQAAAEB+ckvByc/PTz///HO29oMHD8rLy+tvFwUAAAAA+cktBacnnnhC/fv3108//WRrO3jwoAYNGqQnnngiz4oDAAAAgPzgloLT+PHj5eXlpcqVKyssLExhYWGqXLmyihUrpgkTJuR1jQAAAADgULc0HLmfn582bNig5cuX6z//+Y88PT1Vo0YN1a9fP6/rAwAAAACHu6lvnDZt2mQbbtzJyUlNmzZVQECAJkyYoLZt2+qll15SWlrabSkUAAAAABzlpoLT6NGjtXPnTtv8rl271KNHDzVp0kRDhw7VokWLFB0dnedFAgAAAIAj3VRw2rFjhxo3bmybnzt3rmrXrq1PP/1UAwcO1KRJk/TFF1/keZEAAAAA4Eg3FZz++OMPBQYG2ubXrFmj5s2b2+YfeughHTt2LO+qAwAAAIB84KaCU2BgoA4dOiRJSk9P1/bt2xUZGWlbfu7cObm6uuZthQAAAADgYDcVnJo3b66hQ4dq3bp1GjZsmAoXLmw3kt7OnTtVvnz5PC8SAAAAABzppoYjf+utt/T0008rKipK3t7emjFjhtzc3GzL4+Li1LRp0zwvEgAAAAAc6aaCU4kSJbRu3TqdPXtW3t7ecnZ2tls+f/58eXt752mBAAAAAOBot/wHcHPi7+//t4oBAAAAgPzopp5xAgAAAICCiOAEAAAAABYcGpzWrl2r1q1bKzg4WE5OTlq4cOF1+69evVpOTk7Zpn379t2ZggEAAAAUSLf0jFNeOX/+vGrUqKEuXbqobdu2N7ze/v375evra5svUaLE7SgPAAAAACQ5ODi1aNFCLVq0uOn1AgICVKRIkbwvCAAAAABycFc+41SzZk0FBQWpcePGWrVq1XX7pqWlKTU11W4CAAAAgJtxVwWnoKAgffLJJ0pISNCCBQsUHh6uxo0ba+3atbmuEx0dLT8/P9sUEhJyBysGAAAAcC9w6K16Nys8PFzh4eG2+cjISB07dkwTJkxQgwYNclxn2LBhGjhwoG0+NTWV8AQAAADgptxV3zjlpE6dOjpw4ECuy93d3eXr62s3AQAAAMDNuOuDU1JSkoKCghxdBgAAAIB7mENv1fvzzz918OBB2/yhQ4e0Y8cO+fv7q0yZMho2bJiOHz+umTNnSpJiYmJUtmxZVa1aVenp6Zo1a5YSEhKUkJDgqEMAAAAAUAA4NDht3bpVjRo1ss1nPYvUuXNnxcfHKzk5WUePHrUtT09P1+DBg3X8+HF5enqqatWqWrx4sVq2bHnHawcAAABQcDg0ODVs2FDGmFyXx8fH280PGTJEQ4YMuc1VAQAAAIC9u/4ZJwAAAAC43QhOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFlwcXQCAe8PRsfc5ugQUEGXe2OXoEgAABRDfOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFhwaHBau3atWrdureDgYDk5OWnhwoWW66xZs0a1atWSh4eHypUrp6lTp97+QgEAAAAUaA4NTufPn1eNGjX00Ucf3VD/Q4cOqWXLlqpfv76SkpI0fPhw9evXTwkJCbe5UgAAAAAFmYsjd96iRQu1aNHihvtPnTpVZcqUUUxMjCQpIiJCW7du1YQJE9S2bdvbVCUAAACAgu6uesYpMTFRTZs2tWtr1qyZtm7dqoyMjBzXSUtLU2pqqt0EAAAAADfjrgpOKSkpCgwMtGsLDAxUZmamTp06leM60dHR8vPzs00hISF3olQAAAAA95C7KjhJkpOTk928MSbH9izDhg3T2bNnbdOxY8due40AAAAA7i0OfcbpZpUsWVIpKSl2bSdOnJCLi4uKFSuW4zru7u5yd3e/E+UBAAAAuEfdVd84RUZGavny5XZty5Yt04MPPihXV1cHVQUAAADgXufQ4PTnn39qx44d2rFjh6Qrw43v2LFDR48elXTlNrtOnTrZ+vfq1UtHjhzRwIEDtXfvXsXFxSk2NlaDBw92RPkAAAAACgiH3qq3detWNWrUyDY/cOBASVLnzp0VHx+v5ORkW4iSpLCwMC1ZskQDBgzQ5MmTFRwcrEmTJjEUOQAAAIDbyqHBqWHDhrbBHXISHx+frS0qKkrbt2+/jVUBAAAAgL276hknAAAAAHAEghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFF0cXAAAAgHvDmgZRji4BBUTU2jV3fJ984wQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFhwenD7++GOFhYXJw8NDtWrV0rp163Ltu3r1ajk5OWWb9u3bdwcrBgAAAFDQODQ4zZs3T/3799eIESOUlJSk+vXrq0WLFjp69Oh119u/f7+Sk5NtU8WKFe9QxQAAAAAKIocGp/fee0/dunVT9+7dFRERoZiYGIWEhGjKlCnXXS8gIEAlS5a0Tc7OzneoYgAAAAAFkcOCU3p6urZt26amTZvatTdt2lQbNmy47ro1a9ZUUFCQGjdurFWrVl23b1pamlJTU+0mAAAAALgZDgtOp06d0qVLlxQYGGjXHhgYqJSUlBzXCQoK0ieffKKEhAQtWLBA4eHhaty4sdauXZvrfqKjo+Xn52ebQkJC8vQ4AAAAANz7XBxdgJOTk928MSZbW5bw8HCFh4fb5iMjI3Xs2DFNmDBBDRo0yHGdYcOGaeDAgbb51NRUwhMAAACAm+Kwb5yKFy8uZ2fnbN8unThxItu3UNdTp04dHThwINfl7u7u8vX1tZsAAAAA4GY4LDi5ubmpVq1aWr58uV378uXLVbdu3RveTlJSkoKCgvK6PAAAAACwceitegMHDlTHjh314IMPKjIyUp988omOHj2qXr16Sbpym93x48c1c+ZMSVJMTIzKli2rqlWrKj09XbNmzVJCQoISEhIceRgAAAAA7nEODU7t2rXT6dOnNXbsWCUnJ6tatWpasmSJQkNDJUnJycl2f9MpPT1dgwcP1vHjx+Xp6amqVatq8eLFatmypaMOAQAAAEAB4PDBIV5++WW9/PLLOS6Lj4+3mx8yZIiGDBlyB6oCAAAAgP9x6B/ABQAAAIC7AcEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAgsOD08cff6ywsDB5eHioVq1aWrdu3XX7r1mzRrVq1ZKHh4fKlSunqVOn3qFKAQAAABRUDg1O8+bNU//+/TVixAglJSWpfv36atGihY4ePZpj/0OHDqlly5aqX7++kpKSNHz4cPXr108JCQl3uHIAAAAABYlDg9N7772nbt26qXv37oqIiFBMTIxCQkI0ZcqUHPtPnTpVZcqUUUxMjCIiItS9e3d17dpVEyZMuMOVAwAAAChIXBy14/T0dG3btk1Dhw61a2/atKk2bNiQ4zqJiYlq2rSpXVuzZs0UGxurjIwMubq6ZlsnLS1NaWlptvmzZ89KklJTU//uIdhcSvsrz7YFXE9enrd57dzFS44uAQVEfr0OMv/KdHQJKCDy6zUgSeczuQ5wZ+TVdZC1HWOMZV+HBadTp07p0qVLCgwMtGsPDAxUSkpKjuukpKTk2D8zM1OnTp1SUFBQtnWio6M1ZsyYbO0hISF/o3rAMfw+7OXoEgDHi/ZzdAWAQ/m9xjUAyC9vr4Nz587Jz2KbDgtOWZycnOzmjTHZ2qz659SeZdiwYRo4cKBt/vLly/r9999VrFix6+4Ht09qaqpCQkJ07Ngx+fr6OrocwCG4DgCuA0DiOnA0Y4zOnTun4OBgy74OC07FixeXs7Nztm+XTpw4ke1bpSwlS5bMsb+Li4uKFSuW4zru7u5yd3e3aytSpMitF4484+vryxsECjyuA4DrAJC4DhzJ6pumLA4bHMLNzU21atXS8uXL7dqXL1+uunXr5rhOZGRktv7Lli3Tgw8+mOPzTQAAAACQFxw6qt7AgQM1bdo0xcXFae/evRowYICOHj2qXr2uPMcxbNgwderUyda/V69eOnLkiAYOHKi9e/cqLi5OsbGxGjx4sKMOAQAAAEAB4NBnnNq1a6fTp09r7NixSk5OVrVq1bRkyRKFhoZKkpKTk+3+plNYWJiWLFmiAQMGaPLkyQoODtakSZPUtm1bRx0CboG7u7tGjRqV7RZKoCDhOgC4DgCJ6+Bu4mRuZOw9AAAAACjAHHqrHgAAAADcDQhOAAAAAGCB4AQAAAAAFghOAAAAAGCB4HSP2bBhg5ydndW8eXNHl3LbHT58WE5OTnJxcdHx48ftliUnJ8vFxUVOTk46fPiwrT0hIUEPP/yw/Pz85OPjo6pVq2rQoEG25fHx8XJycso2eXh43KnDwt/ENXBFbtdAlqZNm8rZ2VkbN27MtuzFF1/M8TooCK/p3aggnvNZk5+fn+rUqaNFixbZ9ct6L4+IiMi2jS+++EJOTk4qW7asre3SpUuKjo5W5cqV5enpKX9/f9WpU0fTp0+39eG6yJ8K4vm/Y8cOW9u5c+fUsGFDVa5cWceOHXNccQUEwekeExcXp759+2r9+vV2Q7nfDpcuXdLly5dv6z5uRHBwsGbOnGnXNmPGDJUqVcqubcWKFXruuef0zDPPaPPmzdq2bZvGjRun9PR0u36+vr5KTk62m44cOXLbjwN5g2vgipyugSxHjx5VYmKi+vTpo9jY2Bz7NG/ePNt1MGfOnDyvHX9fQTznV6xYoeTkZG3atEm1a9dW27Zt9eOPP9r18fLy0okTJ5SYmGjXHhcXpzJlyti1jR49WjExMXrzzTe1Z88erVq1Sj169NAff/xh14/rIv8piOd/lpMnT6pRo0b6888/tX79eoWEhDi6pHufwT3jzz//ND4+Pmbfvn2mXbt2ZsyYMbZlderUMa+99ppd/xMnThgXFxezcuVKY4wxaWlp5tVXXzXBwcGmcOHCpnbt2mbVqlW2/tOnTzd+fn5m0aJFJiIiwjg7O5uff/7ZbN682Tz22GOmWLFixtfX1zRo0MBs27bNbl979+419erVM+7u7iYiIsIsX77cSDJffvmlrc8vv/xinn32WVOkSBHj7+9vnnjiCXPo0KFcj/fQoUNGkhk5cqSpWLGi3bLw8HDz+uuvG0m2bbzyyiumYcOG130Ns44Rdyeugf/J6RrIMnr0aPPcc8+ZvXv3Gh8fH/Pnn3/aLe/cubNp06ZNrvtF/lFQz/mkpCRbW2pqqpFkJk2alK3uPn36mO7du9vajx07Ztzd3c3QoUNNaGiorb1GjRpm9OjR13upuS7yoYJ8/h89etSEh4ebhg0bmtTUVFufU6dOmeeee86UKlXKeHp6mmrVqpnZs2fbbScqKsr07t3b9O7d2/j5+Rl/f38zYsQIc/nyZVuf0NBQM3bsWNO+fXvj5eVlgoKC7K4xY4yZOHGiqVatmilcuLApXbq0+ec//2nOnTuXa/33Ar5xuofMmzdP4eHhCg8P1wsvvKDp06fL/P8/09WhQwfNmTPHNp/VPzAwUFFRUZKkLl266IcfftDcuXO1c+dO/eMf/1Dz5s114MAB2zoXLlxQdHS0pk2bpt27dysgIEDnzp1T586dtW7dOm3cuFEVK1ZUy5Ytde7cOUnS5cuX9eSTT6pw4cLatGmTPvnkE40YMcKu9gsXLqhRo0by9vbW2rVrtX79enl7e6t58+bZvhG61hNPPKE//vhD69evlyStX79ev//+u1q3bm3Xr2TJktq9e3e2TyVx7+AauP41IEnGGE2fPl0vvPCCKleurEqVKumLL764hVcb+UFBPeezZGRk6NNPP5Ukubq6ZlverVs3zZs3TxcuXJB05Ra+5s2bKzAw0K5fyZIltXLlSp08efKG9ov8oaCe//v371e9evVUuXJlLV26VD4+PrZlFy9eVK1atfTNN9/oxx9/1EsvvaSOHTtq06ZNdtuYMWOGXFxctGnTJk2aNEnvv/++pk2bZtdn/Pjxql69urZv365hw4ZpwIABWr58uW15oUKFNGnSJP3444+aMWOGVq5cqSFDhlj+v93VHBbZkOfq1q1rYmJijDHGZGRkmOLFi5vly5cbY/73KcvatWtt/SMjI82rr75qjDHm4MGDxsnJyRw/ftxum40bNzbDhg0zxlz55EWS2bFjx3XryMzMND4+PmbRokXGGGO+/fZb4+LiYpKTk219rv3kJTY21oSHh9t92pGWlmY8PT3Nd999l+N+rv7kpX///qZLly7GGGO6dOliBgwYYJKSkuw+bf/zzz9Ny5YtjSQTGhpq2rVrZ2JjY83Fixdt28w6Ri8vL7upSZMm1z1m5A9cA9e/BowxZtmyZaZEiRImIyPDGGPM+++/b+rVq2e33c6dOxtnZ+ds18HYsWOve9y48wrqOe/p6Wm8vLxMoUKFjCRTtmxZc/r0aVu/q+8euP/++82MGTPM5cuXTfny5c1XX31l3n//fbtvnHbv3m0iIiJMoUKFzH333Wd69uxplixZYrdvrov8p6Ce/25ubqZhw4YmMzPT8jUyxpiWLVuaQYMG2eajoqJMRESE3b5fe+01ExERYZsPDQ01zZs3t9tOu3btTIsWLXLdzxdffGGKFSt2QzXdrfjG6R6xf/9+bd68Wc8995wkycXFRe3atVNcXJwkqUSJEmrSpIk+//xzSdKhQ4eUmJioDh06SJK2b98uY4wqVaokb29v27RmzRr99NNPtv24ubmpevXqdvs+ceKEevXqpUqVKsnPz09+fn76888/bfca79+/XyEhISpZsqRtndq1a9ttY9u2bTp48KB8fHxs+/b399fFixft9p+bbt26af78+UpJSdH8+fPVtWvXbH28vLy0ePFiHTx4UCNHjpS3t7cGDRqk2rVr2z6NlCQfHx/t2LHDbrr6AWHkT1wD1teAJMXGxqpdu3ZycXGRJLVv316bNm3S/v377fo1atQo23XQu3dvyzpw5xTkc37evHlKSkrS119/rQoVKmjatGny9/fPsW/Xrl01ffp0rVmzRn/++adatmyZrU+VKlX0448/auPGjerSpYt+++03tW7dWt27d7frx3WRfxTk879NmzZav369EhISsi27dOmSxo0bp+rVq6tYsWLy9vbWsmXLsj3/VadOHTk5OdnmIyMjdeDAAV26dMmu7WqRkZHau3evbX7VqlVq0qSJSpUqJR8fH3Xq1EmnT5/W+fPnr1v/3czF0QUgb8TGxiozM9PuYXBjjFxdXfXHH3+oaNGi6tChg1555RV9+OGHmj17tqpWraoaNWpIuvK1srOzs7Zt2yZnZ2e7bXt7e9v+7enpaXehSVdGGjp58qRiYmIUGhoqd3d3RUZG2r5qNsZkW+daly9fVq1atWxvcFcrUaKE5fFXq1ZNlStXVvv27RUREaFq1arZjTpztfLly6t8+fLq3r27RowYoUqVKmnevHnq0qWLpCtfPVeoUMFyn8hfuAasr4Hff/9dCxcuVEZGhqZMmWJrv3TpkuLi4vTuu+/a2ry8vLgO8rmCfM6HhISoYsWKqlixory9vdW2bVvt2bNHAQEB2fp26NBBQ4YM0ejRo9WpUyfbhwbXKlSokB566CE99NBDGjBggGbNmqWOHTtqxIgRCgsLk8R1kZ8U5PN/+PDhql69ujp06CBjjNq1a2dbNnHiRL3//vuKiYnRfffdJy8vL/Xv3/+Gb3+1knVcR44cUcuWLdWrVy+9+eab8vf31/r169WtWzdlZGTkyb7yI4LTPSAzM1MzZ87UxIkT1bRpU7tlbdu21eeff64+ffroySefVM+ePbV06VLNnj1bHTt2tPWrWbOmLl26pBMnTqh+/fo3tf9169bp448/tn2Kd+zYMZ06dcq2vHLlyjp69Kh+++03233lW7ZssdvGAw88oHnz5ikgIEC+vr43tf8sXbt21csvv2z3C6GVsmXLqnDhwvf0pyMFAdfAFVbXwOeff67SpUtr4cKFdu3ff/+9oqOjNW7cuFx/qUT+wjn/P1FRUapWrZrGjRunDz74INtyf39/PfHEE/riiy80derUG95ulSpVJImfD/kQ5780cuRIubi4qEOHDrp8+bLat29vq61NmzZ64YUXJF0JaAcOHMg2NP+1f4oi61mtq0NkTn0qV64sSdq6dasyMzM1ceJEFSp05Qa2AvG8rENuEESe+vLLL42bm5s5c+ZMtmXDhw83999/v23++eefNzVq1DBOTk7myJEjdn07dOhgypYtaxISEmyjxrzzzjtm8eLFxpjcR5y7//77TZMmTcyePXvMxo0bTf369Y2np6d5//33jTFX7v0NDw83zZo1M//5z3/M+vXrzcMPP2wkmYULFxpjjDl//rypWLGiadiwoVm7dq35+eefzerVq02/fv3MsWPHcjzua0dXysjIMCdPnrQ9u3Ht8x2jRo0yr776qlm1apX5+eefzfbt282LL75oPD09zb59+2zH6Ovra5KTk7NNly5durH/ENxxXANJxhjra6BGjRrZRpky5sqoZO7u7rZaOnfubJo3b57tGjh58mQu/wO40zjnk+zav/76a+Pu7m5++eWXHOu+cOGCOXXqlG3+2mec2rZta9577z2zceNGc/jwYbNq1SpTp04dU6lSJdv1xHWRf3D+J9na/vWvfxlnZ2cza9YsY4wx/fv3NyEhIeaHH34we/bsMd27dze+vr52I0JGRUUZb29vM2DAALNv3z4ze/Zs4+XlZaZOnWrrExoaanx9fc27775r9u/fbz766CPj7Oxsli5daoz538+XmJgY89NPP5mZM2eaUqVKGUnmjz/+yPk/7h5AcLoHPP7446Zly5Y5Ltu2bZuRZBsmc/HixUaSadCgQba+6enp5o033jBly5Y1rq6upmTJkuapp54yO3fuNMbk/gayfft28+CDDxp3d3dTsWJFM3/+fBMaGmp7AzHmf8Nyurm5mcqVK5tFixYZSbYL0BhjkpOTTadOnUzx4sWNu7u7KVeunOnRo4c5e/ZsjseW2w/QLNf+0rhy5UrTtm1bExISYtzc3ExgYKBp3ry5WbdunW2drAdBc5qufsgT+QvXQFKOy6++BrZu3Wokmc2bN+fYt3Xr1qZ169bGmCu/IOZ0DYSHh+e4Lu48zvkku/bLly+b8PBw889//vO6dWe5Njh98sknplGjRqZEiRLGzc3NlClTxrz44ovm8OHDtj5cF/kH53+SXfvEiRONs7OzmTlzpjl9+rRp06aN8fb2NgEBAWbkyJGmU6dO2YLTyy+/bHr16mV8fX1N0aJFzdChQ7MNRz5mzBjz7LPPmsKFC5vAwEDbQBxZ3nvvPRMUFGQ8PT1Ns2bNzMyZM+/54ORkzFXjNAJ3yA8//KBHHnlEBw8eVPny5R1dDnDHcQ2goOGcR0GWn87/hg0b6v7771dMTEyufcqWLav+/furf//+d6yuuwE3s+OO+PLLL+Xt7a2KFSvq4MGDeuWVV1SvXj2Hv3kAdwrXAAoaznkUZJz/9yaCE+6Ic+fOaciQITp27JiKFy+uxx57TBMnTnR0WcAdwzWAgoZzHgUZ5/+9iVv1AAAAAMACfwAXAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAA+P9Wr14tJycnnTlz5obXKVu27HX/kCQA4N5AcAIA3DVefPFFOTk5qVevXtmWvfzyy3JyctKLL7545wsDANzzCE4AgLtKSEiI5s6dq7/++svWdvHiRc2ZM0dlypRxYGUAgHsZwQkAcFd54IEHVKZMGS1YsMDWtmDBAoWEhKhmzZq2trS0NPXr108BAQHy8PDQI488oi1btthta8mSJapUqZI8PT3VqFEjHT58ONv+NmzYoAYNGsjT01MhISHq16+fzp8/f9uODwCQPxGcAAB3nS5dumj69Om2+bi4OHXt2tWuz5AhQ5SQkKAZM2Zo+/btqlChgpo1a6bff/9dknTs2DE9/fTTatmypXbs2KHu3btr6NChdtvYtWuXmjVrpqefflo7d+7UvHnztH79evXp0+f2HyQAIF8hOAEA7jodO3bU+vXrdfjwYR05ckQ//PCDXnjhBdvy8+fPa8qUKRo/frxatGihKlWq6NNPP5Wnp6diY2MlSVOmTFG5cuX0/vvvKzw8XB06dMj2fNT48eP1/PPPq3///qpYsaLq1q2rSZMmaebMmbp48eKdPGQAgIO5OLoAAABuVvHixdWqVSvNmDFDxhi1atVKxYsXty3/6aeflJGRoXr16tnaXF1dVbt2be3du1eStHfvXtWpU0dOTk62PpGRkXb72bZtmw4ePKjPP//c1maM0eXLl3Xo0CFFRETcrkMEAOQzBCcAwF2pa9eutlvmJk+ebLfMGCNJdqEoqz2rLavP9Vy+fFk9e/ZUv379si1jIAoAKFi4VQ8AcFdq3ry50tPTlZ6ermbNmtktq1Chgtzc3LR+/XpbW0ZGhrZu3Wr7lqhKlSrauHGj3XrXzj/wwAPavXu3KlSokG1yc3O7TUcGAMiPCE4AgLuSs7Oz9u7dq71798rZ2dlumZeXl/75z3/q1Vdf1dKlS7Vnzx716NFDFy5cULdu3SRJvXr10k8//aSBAwdq//79mj17tuLj4+2289prrykxMVG9e/fWjh07dODAAX399dfq27fvnTpMAEA+QXACANy1fH195evrm+Oyd955R23btlXHjh31wAMP6ODBg/ruu+9UtGhRSVdutUtISNCiRYtUo0YNTZ06VW+//bbdNqpXr641a9bowIEDql+/vmrWrKnXX39dQUFBt/3YAAD5i5O5kZu8AQAAAKAA4xsnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALDw/wCUl+EwJioQ+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2-Layer LSTM Model Evaluation using Normalized grades at the y value\n",
    "print(\"Average MSE for LSTM 2-layers with normalized Grades: \", np.mean(mse_scores))\n",
    "print(\"Average RMSE for LSTM 2-layers with normalized Grades: \", np.mean(rmse_scores))\n",
    "print(\"Average MAE for LSTM 2-layers with normalized Grades: \", np.mean(mae_scores))\n",
    "print(\"Average Kappa for LSTM 2-layers with normalized Grades: \", np.mean(kappa_scores))\n",
    "\n",
    "\n",
    "# Visualize results\n",
    "results = {\n",
    "    \"Average MSE\": np.mean(mse_scores),\n",
    "    \"Average MAE\": np.mean(mae_scores),\n",
    "    \"Average RMSE\": np.mean(rmse_scores),\n",
    "    \"Average Kappa\": np.mean(kappa_scores)\n",
    "}\n",
    "visualize_results(results, f\" Results using LSTM 2-layers with Normalized Grades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ac28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
