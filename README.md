# Automated-AEG-Model-using-NLP-and-ML
Automated essay grading (AEG) is a transformative innovation in education, revolutionizing
the evaluation of written assignments for efficiency and consistency. This project delves into
AEG, harnessing natural language processing, machine learning, and deep learning techniques.
By utilizing a diverse array of features from the extensive Automated Student Assessment Prize
(ASAP) dataset publicly available on Kaggle, the study meticulously evaluates key algorithms,
including Support Vector Machine, Random Forest, and Long Short-Term Memory networks,
in automating essay grading. Notably, both the Random Forest and Long Short-Term Memory
(LSTM) algorithms stand out as front runners, demonstrating remarkable agreement with
human graders. They both achieved an impressive Quadratic Weighted Kappa score of 0.97,
echoing human-grade assessments, although there are distinctions in their MAE performance.
Furthermore, the investigation into grade normalization techniques uncovers their intricate
interplay with model performance and human grading standards. These discoveries offer
invaluable insights to educators and researchers, enabling them to refine automated grading
systems for enhanced consistency and reliability. This study not only advances the field by
shedding light on model selection and deep learning methodologies but also bridges the chasm
between theory and real-world application in educational assessment, making it a pivotal
contribution to the domain.
