{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0867fd",
   "metadata": {},
   "source": [
    "# DATA PROCESSING OF THE ASAP DATASET \n",
    "\n",
    "This code file called \"data_processing.ipynb\" serves as a crucial step in the development of an automated essay grading model. It primarily focuses on data cleaning, preprocessing, and extracting essential features from the ASAP Dataset. The resulting processed data is then stored in a CSV file named \"processed.csv.\" This cleaned and feature-enriched dataset will be utilized as input in the subsequent code file called \"model_training.ipynb\" responsible for building and training the automated essay grading model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef5dc0",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037d610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\yabio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yabio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yabio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import zipfile  # For working with zip files\n",
    "import pandas as pd  # For data manipulation\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns  # For enhanced data visualization\n",
    "%matplotlib inline\n",
    "import re  # For regular expressions\n",
    "from spellchecker import SpellChecker  # For spell checking\n",
    "import warnings  # For suppressing warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from collections import Counter  # For counting elements in a list\n",
    "\n",
    "import nltk  # Natural Language Toolkit for NLP tasks\n",
    "from nltk.corpus import stopwords  # For stop words\n",
    "from nltk.tokenize import word_tokenize  # For word tokenization\n",
    "from nltk import pos_tag  # For part-of-speech tagging\n",
    "\n",
    "# Downloading required NLTK resources for text processing\n",
    "nltk.download('averaged_perceptron_tagger')  # Downloading POS tagger\n",
    "nltk.download('punkt')  # Downloading the Punkt tokenizer\n",
    "nltk.download('stopwords')  # Downloading stop words for text preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9381a6",
   "metadata": {},
   "source": [
    "READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d6d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data from a zip file into a pandas DataFrame.\n",
    "\n",
    "with zipfile.ZipFile(\"./Dataset.zip\") as z:\n",
    "    with z.open(\"training_set_rel3.tsv\") as t:\n",
    "        train_data = pd.read_csv(t, sep='\\t', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d247217",
   "metadata": {},
   "source": [
    "DATA EXPLORATION AND CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b43979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the training data DataFrame.\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277ab7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10295.395808</td>\n",
       "      <td>4.179485</td>\n",
       "      <td>4.127158</td>\n",
       "      <td>4.137408</td>\n",
       "      <td>37.828125</td>\n",
       "      <td>6.800247</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>3.330556</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>2.444154</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635689</td>\n",
       "      <td>2.710297</td>\n",
       "      <td>3.777317</td>\n",
       "      <td>3.589212</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>3.890625</td>\n",
       "      <td>4.078125</td>\n",
       "      <td>3.992188</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6309.074105</td>\n",
       "      <td>2.136913</td>\n",
       "      <td>4.212544</td>\n",
       "      <td>4.264330</td>\n",
       "      <td>5.240829</td>\n",
       "      <td>8.970705</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>0.726807</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>1.211730</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142566</td>\n",
       "      <td>1.045795</td>\n",
       "      <td>0.689401</td>\n",
       "      <td>0.693256</td>\n",
       "      <td>0.643668</td>\n",
       "      <td>0.630390</td>\n",
       "      <td>0.622535</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.603417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4438.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10044.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15681.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set  rater1_domain1  rater2_domain1  \\\n",
       "count  12976.000000  12976.000000    12976.000000    12976.000000   \n",
       "mean   10295.395808      4.179485        4.127158        4.137408   \n",
       "std     6309.074105      2.136913        4.212544        4.264330   \n",
       "min        1.000000      1.000000        0.000000        0.000000   \n",
       "25%     4438.750000      2.000000        2.000000        2.000000   \n",
       "50%    10044.500000      4.000000        3.000000        3.000000   \n",
       "75%    15681.250000      6.000000        4.000000        4.000000   \n",
       "max    21633.000000      8.000000       30.000000       30.000000   \n",
       "\n",
       "       rater3_domain1  domain1_score  rater1_domain2  rater2_domain2  \\\n",
       "count      128.000000   12976.000000     1800.000000     1800.000000   \n",
       "mean        37.828125       6.800247        3.333889        3.330556   \n",
       "std          5.240829       8.970705        0.729103        0.726807   \n",
       "min         20.000000       0.000000        1.000000        1.000000   \n",
       "25%         36.000000       2.000000        3.000000        3.000000   \n",
       "50%         40.000000       3.000000        3.000000        3.000000   \n",
       "75%         40.000000       8.000000        4.000000        4.000000   \n",
       "max         50.000000      60.000000        4.000000        4.000000   \n",
       "\n",
       "       domain2_score  rater1_trait1  ...  rater2_trait3  rater2_trait4  \\\n",
       "count    1800.000000    2292.000000  ...    2292.000000    2292.000000   \n",
       "mean        3.333889       2.444154  ...       2.635689       2.710297   \n",
       "std         0.729103       1.211730  ...       1.142566       1.045795   \n",
       "min         1.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         3.000000       2.000000  ...       2.000000       2.000000   \n",
       "50%         3.000000       2.000000  ...       2.000000       3.000000   \n",
       "75%         4.000000       3.000000  ...       4.000000       3.000000   \n",
       "max         4.000000       6.000000  ...       6.000000       6.000000   \n",
       "\n",
       "       rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "count     723.000000     723.000000     128.000000     128.000000   \n",
       "mean        3.777317       3.589212       3.945312       3.890625   \n",
       "std         0.689401       0.693256       0.643668       0.630390   \n",
       "min         1.000000       1.000000       2.000000       2.000000   \n",
       "25%         3.000000       3.000000       4.000000       4.000000   \n",
       "50%         4.000000       4.000000       4.000000       4.000000   \n",
       "75%         4.000000       4.000000       4.000000       4.000000   \n",
       "max         6.000000       6.000000       6.000000       6.000000   \n",
       "\n",
       "       rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "count     128.000000     128.000000     128.000000     128.000000  \n",
       "mean        4.078125       3.992188       3.843750       3.617188  \n",
       "std         0.622535       0.509687       0.538845       0.603417  \n",
       "min         2.000000       3.000000       2.000000       2.000000  \n",
       "25%         4.000000       4.000000       4.000000       3.000000  \n",
       "50%         4.000000       4.000000       4.000000       4.000000  \n",
       "75%         4.000000       4.000000       4.000000       4.000000  \n",
       "max         6.000000       6.000000       5.000000       5.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate summary statistics of the training data DataFrame.\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3829b62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id              0\n",
       "essay_set             0\n",
       "essay                 0\n",
       "rater1_domain1        0\n",
       "rater2_domain1        0\n",
       "rater3_domain1    12848\n",
       "domain1_score         0\n",
       "rater1_domain2    11176\n",
       "rater2_domain2    11176\n",
       "domain2_score     11176\n",
       "rater1_trait1     10684\n",
       "rater1_trait2     10684\n",
       "rater1_trait3     10684\n",
       "rater1_trait4     10684\n",
       "rater1_trait5     12253\n",
       "rater1_trait6     12253\n",
       "rater2_trait1     10684\n",
       "rater2_trait2     10684\n",
       "rater2_trait3     10684\n",
       "rater2_trait4     10684\n",
       "rater2_trait5     12253\n",
       "rater2_trait6     12253\n",
       "rater3_trait1     12848\n",
       "rater3_trait2     12848\n",
       "rater3_trait3     12848\n",
       "rater3_trait4     12848\n",
       "rater3_trait5     12848\n",
       "rater3_trait6     12848\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count and display the number of missing values (NaN) in each column of the training data.\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7785b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   essay_id        12976 non-null  int64 \n",
      " 1   essay_set       12976 non-null  int64 \n",
      " 2   essay           12976 non-null  object\n",
      " 3   rater1_domain1  12976 non-null  int64 \n",
      " 4   rater2_domain1  12976 non-null  int64 \n",
      " 5   domain1_score   12976 non-null  int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 608.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with missing values and display information about the updated DataFrame.\n",
    "train_data.dropna(axis=1,inplace=True)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554fd03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  domain1_score  \n",
       "0               4               4              8  \n",
       "1               5               4              9  \n",
       "2               4               3              7  \n",
       "3               5               5             10  \n",
       "4               4               4              8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a85711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10295.395808</td>\n",
       "      <td>4.179485</td>\n",
       "      <td>4.127158</td>\n",
       "      <td>4.137408</td>\n",
       "      <td>6.800247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6309.074105</td>\n",
       "      <td>2.136913</td>\n",
       "      <td>4.212544</td>\n",
       "      <td>4.264330</td>\n",
       "      <td>8.970705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4438.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10044.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15681.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set  rater1_domain1  rater2_domain1  \\\n",
       "count  12976.000000  12976.000000    12976.000000    12976.000000   \n",
       "mean   10295.395808      4.179485        4.127158        4.137408   \n",
       "std     6309.074105      2.136913        4.212544        4.264330   \n",
       "min        1.000000      1.000000        0.000000        0.000000   \n",
       "25%     4438.750000      2.000000        2.000000        2.000000   \n",
       "50%    10044.500000      4.000000        3.000000        3.000000   \n",
       "75%    15681.250000      6.000000        4.000000        4.000000   \n",
       "max    21633.000000      8.000000       30.000000       30.000000   \n",
       "\n",
       "       domain1_score  \n",
       "count   12976.000000  \n",
       "mean        6.800247  \n",
       "std         8.970705  \n",
       "min         0.000000  \n",
       "25%         2.000000  \n",
       "50%         3.000000  \n",
       "75%         8.000000  \n",
       "max        60.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e581746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum domain1 score for set1 is 2 and the maximum domain1 score is 12\n",
      "The minimum domain1 score for set2 is 1 and the maximum domain1 score is 6\n",
      "The minimum domain1 score for set3 is 0 and the maximum domain1 score is 3\n",
      "The minimum domain1 score for set4 is 0 and the maximum domain1 score is 3\n",
      "The minimum domain1 score for set5 is 0 and the maximum domain1 score is 4\n",
      "The minimum domain1 score for set6 is 0 and the maximum domain1 score is 4\n",
      "The minimum domain1 score for set7 is 2 and the maximum domain1 score is 24\n",
      "The minimum domain1 score for set8 is 10 and the maximum domain1 score is 60\n"
     ]
    }
   ],
   "source": [
    "# Loop through essay sets and calculate the minimum and maximum domain1 scores for each set.\n",
    "for set_num in range(1, 9):\n",
    "    set_scores = train_data[train_data['essay_set'] == set_num]['domain1_score']\n",
    "    print(\"The minimum domain1 score for set{} is {} and the maximum domain1 score is {}\".format(set_num, min(set_scores), max(set_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0d725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='domain1_score', ylabel='Count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the distribution of domain1 scores to check for skewness.\n",
    "sns.histplot(train_data['domain1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e922ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns and rename 'domain1_score' to 'grade' for clarity.\n",
    "train_data.drop(columns=['rater1_domain1', 'rater2_domain1'],axis=1,inplace=True)\n",
    "train_data.rename(columns={'domain1_score': 'grade'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdfc3e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   grade  \n",
       "0      8  \n",
       "1      9  \n",
       "2      7  \n",
       "3     10  \n",
       "4      8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda47ac",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f67e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_tokenize_essay(essay):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the essay by removing words starting with \"@\", removing stop words, and tokenizing into sentences and words.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        list of list of str: A list of tokenized sentences, where each sentence is a list of tokenized words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Clean the essay by removing words starting with \"@\"\n",
    "    x = [i for i in essay.split() if not i.startswith(\"@\")]\n",
    "    removed_words = ' '.join(x)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(removed_words)\n",
    "    filtered_words = [w for w in word_tokens if w not in stop_words]\n",
    "    \n",
    "    # Tokenize into sentences\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(' '.join(filtered_words))\n",
    "    \n",
    "    # Remove punctuation and tokenize words\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentence_words = re.sub(\"[^A-Za-z0-9]\", \" \", raw_sentence)\n",
    "            words = nltk.word_tokenize(sentence_words)\n",
    "            filtered_sentence_words = [w for w in words if w]\n",
    "            sentences.append(filtered_sentence_words)\n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a1952",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e80bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(essay):\n",
    "    \"\"\"\n",
    "    Count the number of sentences in the essay after preprocessing.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of sentences.\n",
    "    \"\"\"\n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    return len(sentences)\n",
    "\n",
    "def count_words(essay):\n",
    "    \"\"\"\n",
    "    Count the number of words in the essay after preprocessing.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of words.\n",
    "    \"\"\"\n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    word_count = sum(len(sentence) for sentence in sentences)\n",
    "    return word_count\n",
    "\n",
    "def count_unique_words(essay):\n",
    "    \"\"\"\n",
    "    Count the number of unique words in the essay after preprocessing.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of unique words.\n",
    "    \"\"\" \n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    all_words = [word for sentence in sentences for word in sentence]\n",
    "    unique_word_count = len(set(all_words))\n",
    "    return unique_word_count\n",
    "\n",
    "def count_characters(essay):\n",
    "    \"\"\"\n",
    "    Count the number of characters in the essay after preprocessing.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of characters.\n",
    "    \"\"\"\n",
    "    cleaned_essay = preprocess_and_tokenize_essay(essay)\n",
    "    all_words = [word for sentence in cleaned_essay for word in sentence]\n",
    "    total_characters = sum(len(word) for word in all_words)\n",
    "    return total_characters\n",
    "\n",
    "def calculate_average_word_length(essay):\n",
    "    \"\"\"\n",
    "    Calculates the average word length in the essay after preprocessing.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        int: The average word length of essays.\n",
    "    \"\"\"\n",
    "    cleaned_essay = preprocess_and_tokenize_essay(essay)\n",
    "    all_words = [word for sentence in cleaned_essay for word in sentence]\n",
    "    total_characters = sum(len(word) for word in all_words)\n",
    "    total_words = len(all_words)\n",
    "    if total_words > 0:\n",
    "        average_word_length = total_characters / total_words\n",
    "        return average_word_length\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def extract_most_common_words(essay, num_words=10):\n",
    "    \"\"\"\n",
    "    Extracts the most common words from the preprocessed essay.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "        num_words (int): The number of most common words to extract (default is 10).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the most common words and their frequencies.\n",
    "    \"\"\"\n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    all_words = [word for sentence in sentences for word in sentence]\n",
    "    word_counter = Counter(all_words)\n",
    "    most_common_words = word_counter.most_common(num_words)\n",
    "    return most_common_words\n",
    "\n",
    "def count_pos(essay):\n",
    "    \"\"\"\n",
    "    Count parts of speech (POS) in the preprocessed essay.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing counts of different POS tags (Nouns, Verbs, Adjectives, Adverbs, Pronouns,\n",
    "        Prepositions, Conjunctions, and Determiners).\n",
    "    \"\"\"\n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    \n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adj_count = 0\n",
    "    adverb_count = 0\n",
    "    pronoun_count = 0\n",
    "    preposition_count = 0\n",
    "    conjunction_count = 0\n",
    "    determiner_count = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        pos_sentence = nltk.pos_tag(sentence)\n",
    "        for word, pos_tag in pos_sentence:\n",
    "            if pos_tag.startswith('N'):\n",
    "                noun_count += 1\n",
    "            elif pos_tag.startswith('V'):\n",
    "                verb_count += 1\n",
    "            elif pos_tag.startswith('J'):\n",
    "                adj_count += 1\n",
    "            elif pos_tag.startswith('R'):\n",
    "                adverb_count += 1\n",
    "            elif pos_tag.startswith('P'):\n",
    "                pronoun_count += 1\n",
    "            elif pos_tag.startswith('IN'):\n",
    "                preposition_count += 1\n",
    "            elif pos_tag.startswith('CC'):\n",
    "                conjunction_count += 1\n",
    "            elif pos_tag.startswith('DT'):\n",
    "                determiner_count += 1\n",
    "            elif pos_tag.startswith('PDT'):\n",
    "                determiner_count += 1\n",
    "            elif pos_tag.startswith('WDT'):\n",
    "                determiner_count += 1\n",
    "            \n",
    "    return noun_count, verb_count, adj_count, adverb_count, pronoun_count, preposition_count, conjunction_count, determiner_count\n",
    "\n",
    "def count_spelling_errors(essay):\n",
    "    \"\"\"\n",
    "    Count the spelling errors in the preprocessed essay.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        int: The count of misspelled words.\n",
    "    \"\"\"\n",
    "    # Initialize a spell checker\n",
    "    spell_checker = SpellChecker()\n",
    "\n",
    "    # Tokenize the essay into words\n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    \n",
    "    # Count the number of misspelled words\n",
    "    misspelled_count = 0\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word and not spell_checker.correction(word) == word:\n",
    "                misspelled_count += 1\n",
    "    \n",
    "    return misspelled_count\n",
    "\n",
    "\n",
    "def find_misspelled_words(essay):\n",
    "    \"\"\"\n",
    "    Find and return misspelled words in the preprocessed essay along with their positions.\n",
    "\n",
    "    Args:\n",
    "        essay (str): The input essay text.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains a misspelled word and its position.\n",
    "    \"\"\"\n",
    "    # Initialize a spell checker using English dictionary\n",
    "    spell_checker = SpellChecker()\n",
    "    \n",
    "    # Tokenize the essay into words\n",
    "    sentences = preprocess_and_tokenize_essay(essay)\n",
    "    \n",
    "    # Find and store misspelled words along with their positions\n",
    "    misspelled_words = []\n",
    "    for sentence in sentences:\n",
    "        for idx, word in enumerate(sentence):\n",
    "            if not spell_checker.correction(word) == word:\n",
    "                misspelled_words.append((word, idx))\n",
    "    \n",
    "    return misspelled_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be652d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n"
     ]
    }
   ],
   "source": [
    "# Print the first essay in the dataset\n",
    "print(train_data.essay[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad42e2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 16\n",
      "Number of words: 179\n",
      "Number of unique words: 118\n",
      "Number of characters: 935\n",
      "Average word length: 5.223463687150838\n",
      "Noun count: 71\n",
      "Verb count: 43\n",
      "Adjective count: 25\n",
      "Adverb count: 15\n",
      "Pronoun count: 13\n",
      "Preposition count: 5\n",
      "Conjunction count: 0\n",
      "Determiner count: 0\n",
      "Number of spelling errors: 12\n",
      "Misspelled words:\n",
      "Word: 'troble', Position: 26\n",
      "Word: 'buisness', Position: 5\n",
      "Word: 's', Position: 1\n",
      "Word: 'ect', Position: 11\n",
      "Word: 'countrys', Position: 2\n",
      "Word: 's', Position: 4\n",
      "Word: 'll', Position: 15\n",
      "Word: 's', Position: 6\n",
      "Word: 'perpressured', Position: 10\n",
      "Word: 'isnt', Position: 13\n",
      "Word: 'forbidde', Position: 4\n",
      "Word: 'troble', Position: 25\n"
     ]
    }
   ],
   "source": [
    "# Sample essay\n",
    "sample_essay = train_data.essay[0]\n",
    "\n",
    "# Test count_sentences function\n",
    "sentence_count = count_sentences(sample_essay)\n",
    "print(\"Number of sentences:\", sentence_count)\n",
    "\n",
    "# Test count_words function\n",
    "word_count = count_words(sample_essay)\n",
    "print(\"Number of words:\", word_count)\n",
    "\n",
    "# Test count_unique_words function\n",
    "unique_word_count = count_unique_words(sample_essay)\n",
    "print(\"Number of unique words:\", unique_word_count)\n",
    "\n",
    "# Test count_characters function\n",
    "character_count = count_characters(sample_essay)\n",
    "print(\"Number of characters:\", character_count)\n",
    "\n",
    "# Test calculate_average_word_length function\n",
    "average_word_length = calculate_average_word_length(sample_essay)\n",
    "print(\"Average word length:\", average_word_length)\n",
    "\n",
    "# Test count_pos function\n",
    "noun_count, verb_count, adj_count, adverb_count, pronoun_count, preposition_count, conjunction_count, determiner_count = count_pos(sample_essay)\n",
    "print(\"Noun count:\", noun_count)\n",
    "print(\"Verb count:\", verb_count)\n",
    "print(\"Adjective count:\", adj_count)\n",
    "print(\"Adverb count:\", adverb_count)\n",
    "print(\"Pronoun count:\", pronoun_count)\n",
    "print(\"Preposition count:\", preposition_count)\n",
    "print(\"Conjunction count:\", conjunction_count)\n",
    "print(\"Determiner count:\", determiner_count)\n",
    "\n",
    "# Test count_spelling_errors function\n",
    "misspelled_count = count_spelling_errors(sample_essay)\n",
    "print(\"Number of spelling errors:\", misspelled_count)\n",
    "\n",
    "# Test find_misspelled_errors function\n",
    "misspelled_words = find_misspelled_words(sample_essay)\n",
    "\n",
    "if misspelled_words:\n",
    "    print(\"Misspelled words:\")\n",
    "    for word, position in misspelled_words:\n",
    "        print(f\"Word: '{word}', Position: {position}\")\n",
    "else:\n",
    "    print(\"No misspelled words found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4ccfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "\n",
       "   grade  \n",
       "0      8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a4e4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data.copy() # Create a copy of the training data dataframe\n",
    "\n",
    "# Apply preprocessing and tokenization to essays, and calculate various essay statistics\n",
    "df['token_essay'] = df['essay'].apply(preprocess_and_tokenize_essay)\n",
    "df['sentence_count'] = df['essay'].apply(count_sentences)\n",
    "df['word_count'] = df['essay'].apply(count_words)\n",
    "df['unique_word_count'] = df['essay'].apply(count_unique_words)\n",
    "df['character_count'] = df['essay'].apply(count_characters)\n",
    "df['average_word_length'] = df['essay'].apply(calculate_average_word_length)\n",
    "\n",
    "# Apply part-of-speech tagging and count different parts of speech in essays\n",
    "df[['noun_count', 'verb_count', 'adj_count', 'adverb_count', 'pronoun_count', 'preposition_count', 'conjunction_count', 'determiner_count']] = df['essay'].apply(count_pos).apply(pd.Series)\n",
    "\n",
    "# Count misspelled words in essays\n",
    "df['misspelled_count'] = df['essay'].apply(count_spelling_errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b03187",
   "metadata": {},
   "source": [
    "SAVING PROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b22b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataframe to a CSV file\n",
    "df.to_csv(\"processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3902d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>grade</th>\n",
       "      <th>token_essay</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>pronoun_count</th>\n",
       "      <th>preposition_count</th>\n",
       "      <th>conjunction_count</th>\n",
       "      <th>determiner_count</th>\n",
       "      <th>misspelled_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>[[Dear, local, newspaper, I, think, effects, c...</td>\n",
       "      <td>16</td>\n",
       "      <td>179</td>\n",
       "      <td>118</td>\n",
       "      <td>935</td>\n",
       "      <td>5.223464</td>\n",
       "      <td>71</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>[[Dear, I, believe, using, computers, benefit,...</td>\n",
       "      <td>17</td>\n",
       "      <td>235</td>\n",
       "      <td>141</td>\n",
       "      <td>1249</td>\n",
       "      <td>5.314894</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>[[Dear, More, people, use, computers, everyone...</td>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>105</td>\n",
       "      <td>816</td>\n",
       "      <td>5.551020</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>[[Dear, Local, Newspaper, I, found, many, expe...</td>\n",
       "      <td>26</td>\n",
       "      <td>283</td>\n",
       "      <td>186</td>\n",
       "      <td>1678</td>\n",
       "      <td>5.929329</td>\n",
       "      <td>141</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>[[Dear, I, know, computers, positive, effect, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>258</td>\n",
       "      <td>148</td>\n",
       "      <td>1391</td>\n",
       "      <td>5.391473</td>\n",
       "      <td>118</td>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   grade                                        token_essay  sentence_count  \\\n",
       "0      8  [[Dear, local, newspaper, I, think, effects, c...              16   \n",
       "1      9  [[Dear, I, believe, using, computers, benefit,...              17   \n",
       "2      7  [[Dear, More, people, use, computers, everyone...              14   \n",
       "3     10  [[Dear, Local, Newspaper, I, found, many, expe...              26   \n",
       "4      8  [[Dear, I, know, computers, positive, effect, ...              30   \n",
       "\n",
       "   word_count  unique_word_count  character_count  average_word_length  \\\n",
       "0         179                118              935             5.223464   \n",
       "1         235                141             1249             5.314894   \n",
       "2         147                105              816             5.551020   \n",
       "3         283                186             1678             5.929329   \n",
       "4         258                148             1391             5.391473   \n",
       "\n",
       "   noun_count  verb_count  adj_count  adverb_count  pronoun_count  \\\n",
       "0          71          43         25            15             13   \n",
       "1          98          63         25            13             15   \n",
       "2          73          35         23             3              3   \n",
       "3         141          61         37            14              5   \n",
       "4         118          49         24            16              5   \n",
       "\n",
       "   preposition_count  conjunction_count  determiner_count  misspelled_count  \n",
       "0                  5                  0                 0                12  \n",
       "1                  8                  0                 4                17  \n",
       "2                  2                  0                 3                 8  \n",
       "3                  9                  0                 5                27  \n",
       "4                 10                  0                15                20  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the new dataset that would be used for the model training and evaluation\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
